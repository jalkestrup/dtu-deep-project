{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Meta-Llama-3-8B-Instruct:   0%|          | 0/1 [00:00<?, ?it/s]/home/lenovo/alkestrup/venv/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for strombergnlp/danfever contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/strombergnlp/danfever\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/lenovo/alkestrup/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a66c752cef24c238813eae9d4c2820e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.49%       1.894ms        48.21%     184.645ms     721.268us       0.000us         0.00%     100.307ms     391.823us           0 b           0 b       4.34 Gb           0 b           256  \n",
      "                                           aten::linear         0.22%     831.151us        37.28%     142.763ms     637.335us       0.000us         0.00%     100.214ms     447.382us           0 b           0 b       4.34 Gb           0 b           224  \n",
      "                                               aten::mm        23.18%      88.776ms        36.06%     138.097ms     616.503us     100.214ms        73.61%     100.214ms     447.382us           0 b           0 b       4.34 Gb       4.34 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      81.390ms        59.78%      81.390ms     847.811us           0 b           0 b           0 b           0 b            96  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us      18.710ms        13.74%      18.710ms     146.168us           0 b           0 b           0 b           0 b           128  \n",
      "                                              aten::mul         0.75%       2.856ms         2.00%       7.666ms      26.344us      10.517ms         7.73%      10.517ms      36.143us           0 b           0 b       5.00 Gb       5.00 Gb           291  \n",
      "                                            aten::copy_         0.66%       2.541ms         2.27%       8.697ms      24.224us       9.614ms         7.06%       9.614ms      26.779us           0 b           0 b           0 b           0 b           359  \n",
      "                                               aten::to         0.12%     463.994us         2.01%       7.708ms      19.715us       0.000us         0.00%       5.767ms      14.750us           0 b           0 b       2.50 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.33%       1.279ms         1.89%       7.244ms      31.774us       0.000us         0.00%       5.767ms      25.295us           0 b           0 b       2.50 Gb           0 b           228  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.337ms         3.92%       5.337ms      27.652us           0 b           0 b           0 b           0 b           193  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.842ms         2.82%       3.842ms      29.784us           0 b           0 b           0 b           0 b           129  \n",
      "                                            aten::clone         0.09%     345.921us         1.59%       6.084ms      62.085us       0.000us         0.00%       3.660ms      37.346us           0 b           0 b       1.24 Gb           0 b            98  \n",
      "                                              aten::add         0.54%       2.052ms         1.94%       7.436ms      38.327us       3.325ms         2.44%       3.325ms      17.139us           0 b           0 b       1.35 Gb       1.35 Gb           194  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       3.002ms         2.20%       3.002ms      23.269us           0 b           0 b           0 b           0 b           129  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.762ms         2.03%       2.762ms      28.476us           0 b           0 b           0 b           0 b            97  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.630ms         1.93%       2.630ms      40.454us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::cat         0.39%       1.510ms         1.19%       4.554ms      47.437us       2.628ms         1.93%       2.628ms      27.380us           0 b           0 b     521.81 Mb     521.81 Mb            96  \n",
      "                     aten::scaled_dot_product_attention         0.25%     943.106us         1.58%       6.039ms     188.720us       0.000us         0.00%       2.555ms      79.837us           0 b        -512 b     417.36 Mb      -4.98 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.546ms         1.87%       2.546ms      79.548us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.463ms         1.81%       2.463ms      38.487us           0 b           0 b           0 b           0 b            64  \n",
      "                                          aten::reshape         0.23%     861.932us         0.76%       2.915ms       8.189us       0.000us         0.00%       2.391ms       6.716us           0 b           0 b     850.00 Mb           0 b           356  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.11%     416.594us         0.83%       3.173ms      99.157us       0.000us         0.00%       2.296ms      71.759us         512 b           0 b     417.00 Mb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.18%     697.324us         0.63%       2.430ms      75.947us       2.296ms         1.69%       2.296ms      71.759us         512 b           8 b     417.00 Mb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us       2.296ms         1.69%       2.296ms      71.759us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::pow         0.26%       1.009ms         3.03%      11.605ms     178.534us       2.189ms         1.61%       2.189ms      33.684us           0 b           0 b       1.65 Gb       1.65 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.189ms         1.61%       2.189ms      33.684us           0 b           0 b           0 b           0 b            65  \n",
      "                                             aten::silu         0.12%     472.124us         0.82%       3.121ms      97.543us       2.099ms         1.54%       2.099ms      65.585us           0 b           0 b       1.44 Gb       1.44 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.099ms         1.54%       2.099ms      65.585us           0 b           0 b           0 b           0 b            32  \n",
      "                                             aten::mean         0.29%       1.118ms         1.40%       5.360ms      82.462us       1.915ms         1.41%       1.915ms      29.466us           0 b           0 b     422.50 Kb     422.50 Kb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.915ms         1.41%       1.915ms      29.466us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.801ms         1.32%       1.801ms      28.138us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.363ms         1.00%       1.363ms      21.300us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::contiguous         0.01%      50.184us         0.17%     660.152us      20.630us       0.000us         0.00%       1.263ms      39.467us           0 b           0 b     417.00 Mb           0 b            32  \n",
      "                                              aten::neg         0.17%     649.898us         1.41%       5.392ms      84.255us     715.329us         0.53%     715.329us      11.177us           0 b           0 b     261.00 Mb     261.00 Mb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     715.329us         0.53%     715.329us      11.177us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pad         0.04%     158.432us         0.46%       1.753ms      54.790us       0.000us         0.00%     258.472us       8.077us           0 b           0 b       5.69 Mb           0 b            32  \n",
      "                                  aten::constant_pad_nd         0.09%     358.375us         0.42%       1.595ms      49.839us       0.000us         0.00%     258.472us       8.077us           0 b           0 b       5.69 Mb           0 b            32  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     165.249us         0.12%     165.249us       5.164us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     155.455us         0.11%     155.455us       2.392us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.15%     573.767us         0.26%     979.976us      15.077us     140.960us         0.10%     140.960us       2.169us           0 b           0 b     422.50 Kb     422.50 Kb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     140.960us         0.10%     140.960us       2.169us           0 b           0 b           0 b           0 b            65  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     114.205us         0.08%     114.205us       1.784us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::bmm        10.93%      41.878ms        11.36%      43.503ms       1.359ms      93.123us         0.07%      93.123us       2.910us           0 b           0 b     416.00 Kb     416.00 Kb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      93.123us         0.07%      93.123us       2.910us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.12%     441.273us         0.39%       1.492ms      46.631us      88.383us         0.06%      88.383us       2.762us           0 b           0 b     832.00 Kb     832.00 Kb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      88.383us         0.06%      88.383us       2.762us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sin         0.09%     340.587us         0.34%       1.319ms      41.228us      85.473us         0.06%      85.473us       2.671us           0 b           0 b     832.00 Kb     832.00 Kb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      85.473us         0.06%      85.473us       2.671us           0 b           0 b           0 b           0 b            32  \n",
      "                                            aten::fill_         0.08%     299.616us         0.49%       1.887ms      57.184us      75.747us         0.06%      75.747us       2.295us           0 b           0 b           0 b           0 b            33  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      75.747us         0.06%      75.747us       2.295us           0 b           0 b           0 b           0 b            33  \n",
      "                                        aten::embedding         0.02%      71.634us         7.89%      30.230ms      30.230ms       0.000us         0.00%      72.832us      72.832us           0 b           0 b      14.00 Mb           0 b             1  \n",
      "                                     aten::index_select         0.03%      98.809us         7.87%      30.140ms      30.140ms      72.832us         0.05%      72.832us      72.832us           0 b           0 b      14.00 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      72.832us         0.05%      72.832us      72.832us           0 b           0 b           0 b           0 b             1  \n",
      "                                           aten::arange         0.03%     118.823us         0.59%       2.270ms     378.268us       5.889us         0.00%      11.778us       1.963us           0 b           0 b       3.00 Kb           0 b             6  \n",
      "                                              aten::sum         0.03%     100.173us        16.50%      63.178ms      31.589ms      10.496us         0.01%      10.496us       5.248us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      10.496us         0.01%      10.496us       5.248us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::eq         0.09%     349.945us         1.11%       4.257ms       1.064ms       9.568us         0.01%       9.568us       2.392us           0 b           0 b     171.50 Kb     171.50 Kb             4  \n",
      "                                              aten::all         0.03%     127.555us         0.89%       3.412ms       1.706ms       9.504us         0.01%       9.504us       4.752us           0 b           0 b       2.50 Kb       2.50 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       9.504us         0.01%       9.504us       4.752us           0 b           0 b           0 b           0 b             2  \n",
      "                                            aten::index         0.02%      65.771us         1.17%       4.471ms       4.471ms       8.448us         0.01%       8.448us       8.448us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.448us         0.01%       8.448us       8.448us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.00%      10.833us         0.34%       1.297ms     648.260us       0.000us         0.00%       7.426us       3.713us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.00%      13.200us         0.34%       1.286ms     642.843us       0.000us         0.00%       7.426us       3.713us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.02%      63.443us         0.33%       1.272ms     636.243us       7.426us         0.01%       7.426us       3.713us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       7.426us         0.01%       7.426us       3.713us           0 b           0 b           0 b           0 b             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.889us         0.00%       5.889us       1.963us           0 b           0 b           0 b           0 b             3  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.632us         0.00%       5.632us       5.632us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.472us         0.00%       5.472us       5.472us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.184us         0.00%       5.184us       2.592us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::masked_fill         0.01%      35.958us         0.14%     541.431us     541.431us       0.000us         0.00%       4.448us       4.448us           0 b           0 b     169.00 Kb           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.384us         0.00%       4.384us       2.192us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       4.384us         0.00%       4.384us       2.192us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::mul_         0.02%      58.860us         0.75%       2.853ms       2.853ms       4.320us         0.00%       4.320us       4.320us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       4.320us         0.00%       4.320us       4.320us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::triu         0.02%      69.251us         0.36%       1.384ms       1.384ms       3.520us         0.00%       3.520us       3.520us           0 b           0 b       5.50 Kb       5.50 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       3.520us         0.00%       3.520us       3.520us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::gt         0.02%      65.710us         0.70%       2.667ms       2.667ms       3.425us         0.00%       3.425us       3.425us           0 b           0 b       3.00 Kb       3.00 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.425us         0.00%       3.425us       3.425us           0 b           0 b           0 b           0 b             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.392us         0.00%       3.392us       1.696us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::sub         0.00%      15.097us         0.01%      44.650us      44.650us       2.400us         0.00%       2.400us       2.400us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.400us         0.00%       2.400us       2.400us           0 b           0 b           0 b           0 b             1  \n",
      "                                     aten::masked_fill_         0.01%      40.415us         0.11%     414.132us     414.132us       2.240us         0.00%       2.240us       2.240us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.240us         0.00%       2.240us       2.240us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::bitwise_not         0.01%      46.145us         1.69%       6.468ms       6.468ms       2.048us         0.00%       2.048us       2.048us           0 b           0 b       2.00 Kb       2.00 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.048us         0.00%       2.048us       2.048us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.01%      23.469us         0.38%       1.449ms       1.449ms       0.000us         0.00%       1.792us       1.792us           0 b           0 b       5.50 Kb           0 b             1  \n",
      "                                            aten::empty         0.31%       1.172ms         0.31%       1.172ms       4.440us       0.000us         0.00%       0.000us       0.000us      26.49 Kb      26.49 Kb       1.65 Gb       1.65 Gb           264  \n",
      "                                       aten::lift_fresh         0.00%       1.186us         0.00%       1.186us       0.593us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       1.115us         0.00%       1.115us       0.558us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         0.51%       1.953ms         0.66%       2.547ms      11.120us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.50 Gb       2.50 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.05%     207.460us         0.05%     207.460us      34.577us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize         0.01%      46.837us         0.01%      46.837us      11.709us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us     -26.00 Kb     -26.00 Kb     -18.48 Gb     -18.48 Gb          1636  \n",
      "                                             aten::view         0.10%     385.727us         0.10%     385.727us       0.916us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.01%      56.691us         0.09%     355.712us      88.928us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      14.00 Mb      14.00 Mb             4  \n",
      "                                  cudaStreamIsCapturing         0.02%      94.407us         0.02%      94.407us       2.009us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            47  \n",
      "                                             cudaMalloc         1.61%       6.161ms         1.61%       6.161ms     342.302us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            18  \n",
      "                                       cudaLaunchKernel        42.10%     161.249ms        42.10%     161.249ms     107.285us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1503  \n",
      "                                        aten::unsqueeze         0.15%     564.184us         0.19%     732.851us       3.200us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.28%       1.055ms         0.28%       1.055ms       0.662us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1593  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 382.979ms\n",
      "Self CUDA time total: 136.139ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.07%     977.095us        10.66%     143.343ms     559.935us       0.000us         0.00%     988.227ms       3.860ms           0 b           0 b      42.00 Gb           0 b           256  \n",
      "                                           aten::linear         0.03%     469.467us        10.65%     143.208ms     639.323us       0.000us         0.00%     988.128ms       4.411ms           0 b           0 b      42.00 Gb           0 b           224  \n",
      "                                               aten::mm         0.35%       4.723ms        10.47%     140.757ms     628.379us     988.128ms        72.81%     988.128ms       4.411ms           0 b           0 b      42.00 Gb      42.00 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us     559.216ms        41.21%     559.216ms       8.738ms           0 b           0 b           0 b           0 b            64  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us     240.106ms        17.69%     240.106ms       7.503ms           0 b           0 b           0 b           0 b            32  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us     149.884ms        11.04%     149.884ms       2.342ms           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::mul         0.12%       1.583ms        12.19%     163.846ms     563.046us     100.679ms         7.42%     100.679ms     345.976us           0 b           0 b      48.39 Gb      48.39 Gb           291  \n",
      "                                            aten::copy_         0.08%       1.116ms         3.77%      50.650ms     154.893us      84.366ms         6.22%      84.366ms     257.999us           0 b           0 b           0 b           0 b           327  \n",
      "                     aten::scaled_dot_product_attention         0.03%     409.285us         0.42%       5.617ms     175.538us       0.000us         0.00%      68.512ms       2.141ms          32 b        -448 b       4.00 Gb           0 b            32  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.02%     235.629us         0.38%       5.154ms     161.056us       0.000us         0.00%      68.512ms       2.141ms         512 b           0 b       4.00 Gb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.04%     502.604us         0.35%       4.745ms     148.283us      68.512ms         5.05%      68.512ms       2.141ms         512 b          16 b       4.00 Gb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us      68.512ms         5.05%      68.512ms       2.141ms           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      49.493ms         3.65%      49.493ms     256.438us           0 b           0 b           0 b           0 b           193  \n",
      "                                               aten::to         0.02%     286.165us         1.69%      22.690ms      58.030us       0.000us         0.00%      49.404ms     126.353us           0 b           0 b      24.38 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.05%     636.913us         1.67%      22.404ms      98.262us       0.000us         0.00%      49.404ms     216.684us           0 b           0 b      24.38 Gb           0 b           228  \n",
      "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      38.459ms         2.83%      38.459ms     600.928us           0 b           0 b           0 b           0 b            64  \n",
      "                                            aten::clone         0.02%     227.855us         2.31%      31.062ms     316.958us       0.000us         0.00%      34.944ms     356.573us           0 b           0 b      12.03 Gb           0 b            98  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      34.922ms         2.57%      34.922ms     360.022us           0 b           0 b           0 b           0 b            97  \n",
      "                                              aten::add         0.08%       1.045ms         2.66%      35.796ms     184.516us      31.838ms         2.35%      31.838ms     164.111us           0 b           0 b      13.02 Gb      13.02 Gb           194  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      26.466ms         1.95%      26.466ms     827.055us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      24.853ms         1.83%      24.853ms     256.212us           0 b           0 b           0 b           0 b            97  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      24.668ms         1.82%      24.668ms     379.513us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      24.532ms         1.81%      24.532ms     190.169us           0 b           0 b           0 b           0 b           129  \n",
      "                                          aten::reshape         0.04%     503.945us         2.15%      28.833ms      80.993us       0.000us         0.00%      23.291ms      65.424us           0 b           0 b       8.00 Gb           0 b           356  \n",
      "                                              aten::cat         0.06%     795.663us         0.46%       6.135ms      63.907us      22.507ms         1.66%      22.507ms     234.445us           0 b           0 b       5.01 Gb       5.01 Gb            96  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      22.302ms         1.64%      22.302ms     348.474us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pow         0.04%     524.745us         0.63%       8.429ms     129.679us      20.756ms         1.53%      20.756ms     319.328us           0 b           0 b      16.25 Gb      16.25 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      20.756ms         1.53%      20.756ms     319.328us           0 b           0 b           0 b           0 b            65  \n",
      "                                             aten::silu         0.02%     278.414us         7.24%      97.304ms       3.041ms      20.729ms         1.53%      20.729ms     647.776us           0 b           0 b      14.00 Gb      14.00 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      20.729ms         1.53%      20.729ms     647.776us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      16.370ms         1.21%      16.370ms     255.785us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.208ms         1.12%      15.208ms     237.630us           0 b           0 b           0 b           0 b            64  \n",
      "                                             aten::mean         0.05%     621.095us         0.70%       9.432ms     145.115us      11.675ms         0.86%      11.675ms     179.618us           0 b           0 b       4.06 Mb       4.06 Mb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      11.675ms         0.86%      11.675ms     179.618us           0 b           0 b           0 b           0 b            65  \n",
      "                                       aten::contiguous         0.00%      30.237us         0.22%       2.892ms      90.378us       0.000us         0.00%      11.606ms     362.688us           0 b           0 b       4.00 Gb           0 b            32  \n",
      "                                              aten::neg         0.03%     397.897us         0.42%       5.695ms      88.986us       6.636ms         0.49%       6.636ms     103.680us           0 b           0 b       2.50 Gb       2.50 Gb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.636ms         0.49%       6.636ms     103.680us           0 b           0 b           0 b           0 b            64  \n",
      "                                        aten::embedding         0.00%      16.616us         0.04%     586.978us     586.978us       0.000us         0.00%     697.125us     697.125us           0 b           0 b     128.00 Mb           0 b             1  \n",
      "                                     aten::index_select         0.00%      40.999us         0.04%     559.148us     559.148us     697.125us         0.05%     697.125us     697.125us           0 b           0 b     128.00 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     697.125us         0.05%     697.125us     697.125us           0 b           0 b           0 b           0 b             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     462.654us         0.03%     462.654us       2.410us           0 b           0 b           0 b           0 b           192  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     204.416us         0.02%     204.416us       6.388us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     202.243us         0.01%     202.243us       3.111us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.02%     326.560us         0.04%     563.950us       8.676us     167.044us         0.01%     167.044us       2.570us           0 b           0 b       4.06 Mb       4.06 Mb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     167.044us         0.01%     167.044us       2.570us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::sin         0.02%     203.781us         0.16%       2.139ms      66.836us     101.407us         0.01%     101.407us       3.169us           0 b           0 b       8.00 Mb       8.00 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     101.407us         0.01%     101.407us       3.169us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.02%     238.300us         0.10%       1.308ms      40.861us     100.481us         0.01%     100.481us       3.140us           0 b           0 b       8.00 Mb       8.00 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     100.481us         0.01%     100.481us       3.140us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::bmm         0.06%     800.029us         0.07%     968.764us      30.274us      98.563us         0.01%      98.563us       3.080us           0 b           0 b       4.00 Mb       4.00 Mb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      98.563us         0.01%      98.563us       3.080us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      56.705us         0.00%      56.705us      56.705us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      52.417us         0.00%      52.417us      52.417us           0 b           0 b           0 b           0 b             1  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      39.457us         0.00%      39.457us      19.728us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::masked_fill         0.00%       6.678us         0.00%      53.701us      53.701us       0.000us         0.00%      39.072us      39.072us           0 b           0 b      16.00 Mb           0 b             1  \n",
      "                                               aten::eq         0.01%      80.733us         0.04%     502.131us     125.533us      36.351us         0.00%      36.351us       9.088us           0 b           0 b      16.02 Mb      16.02 Mb             4  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      30.240us         0.00%      30.240us      15.120us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::all         0.00%      34.057us         0.00%      46.257us      23.129us      22.176us         0.00%      22.176us      11.088us           0 b           0 b      16.50 Kb      16.50 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      22.176us         0.00%      22.176us      11.088us           0 b           0 b           0 b           0 b             2  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      19.616us         0.00%      19.616us       9.808us           0 b           0 b           0 b           0 b             2  \n",
      "                                     aten::masked_fill_         0.00%      12.109us         0.00%      18.200us      18.200us      17.088us         0.00%      17.088us      17.088us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      17.088us         0.00%      17.088us      17.088us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::sum         0.00%      36.710us         0.00%      57.103us      28.552us      13.728us         0.00%      13.728us       6.864us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      13.728us         0.00%      13.728us       6.864us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::arange         0.00%      50.149us         0.01%     156.729us      26.121us       5.952us         0.00%      11.904us       1.984us           0 b           0 b      17.00 Kb           0 b             6  \n",
      "                                            aten::index         0.00%      28.247us         0.00%      46.350us      46.350us      10.240us         0.00%      10.240us      10.240us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.240us         0.00%      10.240us      10.240us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.00%       8.160us        59.93%     805.493ms     402.747ms       0.000us         0.00%       7.776us       3.888us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.00%       7.346us        59.93%     805.485ms     402.743ms       0.000us         0.00%       7.776us       3.888us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.00%      27.534us        59.92%     805.478ms     402.739ms       7.776us         0.00%       7.776us       3.888us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       7.776us         0.00%       7.776us       3.888us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.111us         0.00%       6.111us       3.055us           0 b           0 b           0 b           0 b             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.952us         0.00%       5.952us       1.984us           0 b           0 b           0 b           0 b             3  \n",
      "                                             aten::mul_         0.00%      15.581us         0.00%      24.608us      24.608us       5.696us         0.00%       5.696us       5.696us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.696us         0.00%       5.696us       5.696us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::triu         0.00%      23.152us         0.01%     160.163us     160.163us       4.768us         0.00%       4.768us       4.768us           0 b           0 b     512.00 Kb     512.00 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       4.768us         0.00%       4.768us       4.768us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::gt         0.00%      18.145us         0.00%      25.493us      25.493us       4.544us         0.00%       4.544us       4.544us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.544us         0.00%       4.544us       4.544us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::sub         0.00%      14.168us         0.00%      20.779us      20.779us       2.368us         0.00%       2.368us       2.368us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.368us         0.00%       2.368us       2.368us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.00%       8.709us         0.00%      28.598us      28.598us       0.000us         0.00%       2.176us       2.176us           0 b           0 b     512.00 Kb           0 b             1  \n",
      "                                            aten::fill_         0.00%       9.729us         0.00%      16.711us      16.711us       2.176us         0.00%       2.176us       2.176us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.176us         0.00%       2.176us       2.176us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::bitwise_not         0.00%      11.261us         0.00%      17.626us      17.626us       2.176us         0.00%       2.176us       2.176us           0 b           0 b      16.00 Kb      16.00 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.176us         0.00%       2.176us       2.176us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::empty         0.05%     605.997us         0.05%     605.997us       2.612us       0.000us         0.00%       0.000us       0.000us     256.48 Kb     256.48 Kb      16.02 Gb      16.02 Gb           232  \n",
      "                                       aten::lift_fresh         0.00%       1.231us         0.00%       1.231us       0.615us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       0.911us         0.00%       0.911us       0.456us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         0.09%       1.248ms         0.11%       1.460ms       6.375us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      24.40 Gb      24.40 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.01%     183.019us         0.01%     183.019us      30.503us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize        59.92%     805.433ms        59.92%     805.433ms     201.358ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us    -256.03 Kb    -256.03 Kb    -179.63 Gb    -179.63 Gb          1638  \n",
      "                                             aten::view         0.02%     229.502us         0.02%     229.502us       0.545us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.00%      32.940us         0.04%     480.058us     120.015us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     128.01 Mb     128.01 Mb             4  \n",
      "                                  cudaStreamIsCapturing         0.00%      55.104us         0.00%      55.104us       1.198us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            46  \n",
      "                                             cudaMalloc         0.26%       3.509ms         0.26%       3.509ms     250.668us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            14  \n",
      "                                       cudaLaunchKernel        29.08%     390.866ms        29.08%     390.866ms     265.715us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1471  \n",
      "                                        aten::unsqueeze         0.03%     347.715us         0.03%     452.857us       1.978us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.05%     627.155us         0.05%     627.155us       0.410us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1529  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.344s\n",
      "Self CUDA time total: 1.357s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.92%       2.300ms        10.13%      25.346ms      99.006us       0.000us         0.00%     206.029ms     804.799us           0 b           0 b       8.86 Gb           0 b           256  \n",
      "                                           aten::linear         0.45%       1.114ms        10.23%      25.601ms     114.292us       0.000us         0.00%     205.930ms     919.330us           0 b           0 b       8.86 Gb           0 b           224  \n",
      "                                               aten::mm         3.91%       9.788ms         7.75%      19.383ms      86.533us     205.930ms        74.20%     205.930ms     919.330us           0 b           0 b       8.86 Gb       8.86 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us     167.317ms        60.29%     167.317ms       1.743ms           0 b           0 b           0 b           0 b            96  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us      29.850ms        10.76%      29.850ms     466.410us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::mul         1.35%       3.386ms         3.98%       9.961ms      34.230us      21.500ms         7.75%      21.500ms      73.884us           0 b           0 b      10.21 Gb      10.21 Gb           291  \n",
      "                                            aten::copy_         1.23%       3.085ms         2.65%       6.638ms      18.489us      18.800ms         6.77%      18.800ms      52.367us           0 b           0 b           0 b           0 b           359  \n",
      "                                               aten::to         0.24%     593.993us         3.64%       9.110ms      23.300us       0.000us         0.00%      11.130ms      28.465us           0 b           0 b       5.14 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.66%       1.652ms         3.40%       8.516ms      37.353us       0.000us         0.00%      11.130ms      48.814us           0 b           0 b       5.14 Gb           0 b           228  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      10.779ms         3.88%      10.779ms      55.849us           0 b           0 b           0 b           0 b           193  \n",
      "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us       8.477ms         3.05%       8.477ms     132.448us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.665ms         2.76%       7.665ms      59.416us           0 b           0 b           0 b           0 b           129  \n",
      "                                            aten::clone         0.17%     430.520us         1.22%       3.047ms      31.089us       0.000us         0.00%       7.448ms      76.002us           0 b           0 b       2.53 Gb           0 b            98  \n",
      "                                              aten::add         0.98%       2.458ms         1.55%       3.881ms      20.006us       6.849ms         2.47%       6.849ms      35.306us           0 b           0 b       2.74 Gb       2.74 Gb           194  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.622ms         2.03%       5.622ms      43.579us           0 b           0 b           0 b           0 b           129  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.569ms         2.01%       5.569ms     174.016us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.502ms         1.98%       5.502ms      56.717us           0 b           0 b           0 b           0 b            97  \n",
      "                     aten::scaled_dot_product_attention         0.40%     993.574us         2.34%       5.861ms     183.159us       0.000us         0.00%       5.359ms     167.475us           0 b        -512 b     864.74 Mb     -22.15 Mb            32  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.146ms         1.85%       5.146ms      79.174us           0 b           0 b           0 b           0 b            65  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.18%     446.339us         1.02%       2.564ms      80.122us       0.000us         0.00%       5.041ms     157.516us         512 b           0 b     864.00 Mb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.32%     788.122us         0.69%       1.731ms      54.105us       5.041ms         1.82%       5.041ms     157.516us         512 b           0 b     864.00 Mb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us       5.041ms         1.82%       5.041ms     157.516us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cat         0.69%       1.720ms         1.03%       2.583ms      26.911us       4.994ms         1.80%       4.994ms      52.024us           0 b           0 b       1.06 Gb       1.06 Gb            96  \n",
      "                                          aten::reshape         0.44%       1.104ms         1.47%       3.689ms      10.363us       0.000us         0.00%       4.921ms      13.823us           0 b           0 b       1.69 Gb           0 b           356  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       4.811ms         1.73%       4.811ms      75.177us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pow         0.45%       1.115ms         0.66%       1.656ms      25.476us       4.392ms         1.58%       4.392ms      67.573us           0 b           0 b       3.43 Gb       3.43 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.392ms         1.58%       4.392ms      67.573us           0 b           0 b           0 b           0 b            65  \n",
      "                                             aten::silu         0.24%     592.257us         2.18%       5.456ms     170.491us       4.365ms         1.57%       4.365ms     136.399us           0 b           0 b       2.95 Gb       2.95 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.365ms         1.57%       4.365ms     136.399us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.585ms         1.29%       3.585ms      56.014us           0 b           0 b           0 b           0 b            64  \n",
      "                                             aten::mean         0.50%       1.251ms         0.68%       1.701ms      26.175us       3.394ms         1.22%       3.394ms      52.220us           0 b           0 b     877.50 Kb     877.50 Kb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       3.394ms         1.22%       3.394ms      52.220us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.085ms         1.11%       3.085ms      48.206us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::contiguous         0.02%      60.566us         0.34%     841.581us      26.299us       0.000us         0.00%       2.520ms      78.764us           0 b           0 b     864.00 Mb           0 b            32  \n",
      "                                              aten::neg         0.30%     744.877us         0.48%       1.201ms      18.773us       1.508ms         0.54%       1.508ms      23.570us           0 b           0 b     570.50 Mb     570.50 Mb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.508ms         0.54%       1.508ms      23.570us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pad         0.07%     169.767us         0.84%       2.097ms      65.534us       0.000us         0.00%     318.692us       9.959us           0 b           0 b      23.62 Mb           0 b            32  \n",
      "                                  aten::constant_pad_nd         0.17%     413.121us         0.77%       1.927ms      60.228us       0.000us         0.00%     318.692us       9.959us           0 b           0 b      23.62 Mb           0 b            32  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     286.048us         0.10%     286.048us       2.235us           0 b           0 b           0 b           0 b           128  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     182.978us         0.07%     182.978us       5.718us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     172.769us         0.06%     172.769us       2.658us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.27%     663.286us         0.86%       2.152ms      33.112us     156.030us         0.06%     156.030us       2.400us           0 b           0 b     877.50 Kb     877.50 Kb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     156.030us         0.06%     156.030us       2.400us           0 b           0 b           0 b           0 b            65  \n",
      "                                        aten::embedding         0.01%      20.833us         0.07%     182.226us     182.226us       0.000us         0.00%     145.665us     145.665us           0 b           0 b      27.00 Mb           0 b             1  \n",
      "                                     aten::index_select         0.02%      57.470us         0.06%     146.487us     146.487us     145.665us         0.05%     145.665us     145.665us           0 b           0 b      27.00 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     145.665us         0.05%     145.665us     145.665us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::fill_         0.12%     311.807us         0.23%     581.911us      17.634us     101.220us         0.04%     101.220us       3.067us           0 b           0 b           0 b           0 b            33  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     101.220us         0.04%     101.220us       3.067us           0 b           0 b           0 b           0 b            33  \n",
      "                                              aten::bmm         0.68%       1.697ms         0.86%       2.161ms      67.536us      98.593us         0.04%      98.593us       3.081us           0 b           0 b     864.00 Kb     864.00 Kb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      98.593us         0.04%      98.593us       3.081us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.20%     508.021us         0.31%     779.729us      24.367us      94.272us         0.03%      94.272us       2.946us           0 b           0 b       1.69 Mb       1.69 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      94.272us         0.03%      94.272us       2.946us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sin         0.15%     374.865us         0.25%     614.441us      19.201us      90.178us         0.03%      90.178us       2.818us           0 b           0 b       1.69 Mb       1.69 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      90.178us         0.03%      90.178us       2.818us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sum         0.05%     135.534us         0.08%     204.090us     102.045us      12.513us         0.00%      12.513us       6.257us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.513us         0.00%      12.513us       6.257us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::arange         0.03%      86.923us         0.13%     317.751us      52.959us       5.759us         0.00%      11.518us       1.920us           0 b           0 b       5.00 Kb           0 b             6  \n",
      "                                              aten::all         0.03%      63.917us         0.03%      87.471us      43.735us      11.264us         0.00%      11.264us       5.632us           0 b           0 b       4.00 Kb       4.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      11.264us         0.00%      11.264us       5.632us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::eq         0.05%     128.458us         0.07%     184.504us      46.126us      10.688us         0.00%      10.688us       2.672us           0 b           0 b     733.00 Kb     733.00 Kb             4  \n",
      "                                            aten::index         0.02%      54.796us         0.03%      82.807us      82.807us       9.952us         0.00%       9.952us       9.952us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.952us         0.00%       9.952us       9.952us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.592us         0.00%       6.592us       6.592us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.464us         0.00%       6.464us       6.464us           0 b           0 b           0 b           0 b             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       6.400us         0.00%       6.400us       3.200us           0 b           0 b           0 b           0 b             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.759us         0.00%       5.759us       1.920us           0 b           0 b           0 b           0 b             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.504us         0.00%       5.504us       2.752us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::masked_fill         0.00%       9.738us         0.04%      92.199us      92.199us       0.000us         0.00%       5.408us       5.408us           0 b           0 b     729.00 Kb           0 b             1  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.280us         0.00%       5.280us       2.640us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.184us         0.00%       5.184us       2.592us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::mul_         0.01%      21.093us         0.01%      32.368us      32.368us       5.056us         0.00%       5.056us       5.056us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.056us         0.00%       5.056us       5.056us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.01%      14.760us        66.97%     167.557ms      83.778ms       0.000us         0.00%       3.648us       1.824us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.01%      15.144us        66.97%     167.542ms      83.771ms       0.000us         0.00%       3.648us       1.824us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.03%      67.739us        66.96%     167.527ms      83.763ms       3.648us         0.00%       3.648us       1.824us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       3.648us         0.00%       3.648us       1.824us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::triu         0.01%      21.860us         0.01%      32.649us      32.649us       3.488us         0.00%       3.488us       3.488us           0 b           0 b      23.00 Kb      23.00 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       3.488us         0.00%       3.488us       3.488us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::gt         0.01%      26.346us         0.01%      37.265us      37.265us       3.424us         0.00%       3.424us       3.424us           0 b           0 b      11.50 Kb      11.50 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.424us         0.00%       3.424us       3.424us           0 b           0 b           0 b           0 b             1  \n",
      "                                     aten::masked_fill_         0.01%      19.336us         0.01%      30.973us      30.973us       2.752us         0.00%       2.752us       2.752us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.752us         0.00%       2.752us       2.752us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::sub         0.01%      28.157us         0.02%      42.986us      42.986us       2.272us         0.00%       2.272us       2.272us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.272us         0.00%       2.272us       2.272us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::bitwise_not         0.01%      16.777us         0.01%      26.406us      26.406us       1.984us         0.00%       1.984us       1.984us           0 b           0 b       3.50 Kb       3.50 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.984us         0.00%       1.984us       1.984us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.00%      10.852us         0.02%      54.639us      54.639us       0.000us         0.00%       1.728us       1.728us           0 b           0 b      23.00 Kb           0 b             1  \n",
      "                                            aten::empty         0.57%       1.418ms         0.57%       1.418ms       5.370us       0.000us         0.00%       0.000us       0.000us      54.50 Kb      54.50 Kb       3.40 Gb       3.40 Gb           264  \n",
      "                                       aten::lift_fresh         0.00%       1.975us         0.00%       1.975us       0.988us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       1.439us         0.00%       1.439us       0.720us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         0.90%       2.247ms         0.90%       2.247ms       9.811us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.14 Gb       5.14 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.09%     229.361us         0.09%     229.361us      38.227us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize        66.97%     167.544ms        66.97%     167.544ms      41.886ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us     -54.00 Kb     -54.00 Kb     -37.91 Gb     -37.91 Gb          1635  \n",
      "                                             aten::view         0.19%     475.482us         0.19%     475.482us       1.129us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.02%      44.805us         0.02%      44.805us      11.201us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      27.00 Mb      27.00 Mb             4  \n",
      "                                       cudaLaunchKernel         9.37%      23.436ms         9.37%      23.436ms      14.956us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1567  \n",
      "                                        aten::unsqueeze         0.28%     690.905us         0.36%     888.889us       3.882us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.55%       1.371ms         0.55%       1.371ms       0.861us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1593  \n",
      "                                            aten::slice         0.74%       1.852ms         0.91%       2.271ms       3.472us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           654  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 250.191ms\n",
      "Self CUDA time total: 277.533ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.09%       1.122ms        24.96%     324.276ms       1.267ms       0.000us         0.00%        1.000s       3.906ms           0 b           0 b      42.00 Gb           0 b           256  \n",
      "                                           aten::linear         0.03%     454.006us        24.70%     320.980ms       1.433ms       0.000us         0.00%     999.957ms       4.464ms           0 b           0 b      42.00 Gb           0 b           224  \n",
      "                                               aten::mm         0.34%       4.362ms        24.48%     318.141ms       1.420ms     999.957ms        76.24%     999.957ms       4.464ms           0 b           0 b      42.00 Gb      42.00 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us     566.232ms        43.17%     566.232ms       8.847ms           0 b           0 b           0 b           0 b            64  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us     243.059ms        18.53%     243.059ms       7.596ms           0 b           0 b           0 b           0 b            32  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us     151.275ms        11.53%     151.275ms       2.364ms           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::mul         0.12%       1.577ms         5.85%      75.984ms     262.015us     101.153ms         7.71%     101.153ms     348.803us           0 b           0 b      48.38 Gb      48.38 Gb           290  \n",
      "                                            aten::copy_         0.08%       1.087ms         1.39%      18.031ms      61.750us      73.235ms         5.58%      73.235ms     250.803us           0 b           0 b           0 b           0 b           292  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      49.857ms         3.80%      49.857ms     258.328us           0 b           0 b           0 b           0 b           193  \n",
      "                                               aten::to         0.02%     250.529us         1.52%      19.811ms      50.668us       0.000us         0.00%      49.780ms     127.315us           0 b           0 b      24.38 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.05%     698.814us         1.51%      19.561ms      85.792us       0.000us         0.00%      49.780ms     218.333us           0 b           0 b      24.38 Gb           0 b           228  \n",
      "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      38.926ms         2.97%      38.926ms     608.221us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::add         0.08%       1.097ms         0.90%      11.689ms      60.565us      31.869ms         2.43%      31.869ms     165.126us           0 b           0 b      13.00 Gb      13.00 Gb           193  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      26.474ms         2.02%      26.474ms     827.320us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      25.038ms         1.91%      25.038ms     258.127us           0 b           0 b           0 b           0 b            97  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      24.821ms         1.89%      24.821ms     381.869us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      24.723ms         1.88%      24.723ms     191.650us           0 b           0 b           0 b           0 b           129  \n",
      "                                          aten::reshape         0.04%     572.838us         0.15%       1.909ms       5.407us       0.000us         0.00%      23.455ms      66.443us           0 b           0 b       8.00 Gb           0 b           353  \n",
      "                                            aten::clone         0.01%     190.709us         0.09%       1.113ms      17.389us       0.000us         0.00%      23.455ms     366.477us           0 b           0 b       8.00 Gb           0 b            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      23.455ms         1.79%      23.455ms     366.477us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::cat         0.07%     882.877us         0.89%      11.626ms     121.102us      22.662ms         1.73%      22.662ms     236.062us           0 b           0 b       5.01 Gb       5.01 Gb            96  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      22.455ms         1.71%      22.455ms     350.864us           0 b           0 b           0 b           0 b            64  \n",
      "                     aten::scaled_dot_product_attention         0.04%     567.670us         0.69%       8.945ms     279.524us       0.000us         0.00%      21.434ms     669.815us           0 b        -512 b       4.00 Gb     -64.00 Mb            32  \n",
      "              aten::_scaled_dot_product_flash_attention         0.02%     281.662us         0.64%       8.377ms     261.784us       0.000us         0.00%      21.434ms     669.815us         512 b           0 b       4.06 Gb           0 b            32  \n",
      "                         aten::_flash_attention_forward         0.05%     648.494us         0.60%       7.837ms     244.902us      21.434ms         1.63%      21.434ms     669.815us         512 b           0 b       4.06 Gb           0 b            32  \n",
      "void pytorch_flash::flash_fwd_kernel<pytorch_flash::...         0.00%       0.000us         0.00%       0.000us       0.000us      21.434ms         1.63%      21.434ms     669.815us           0 b           0 b           0 b           0 b            32  \n",
      "                                             aten::silu         0.02%     261.737us         0.34%       4.430ms     138.433us      20.930ms         1.60%      20.930ms     654.070us           0 b           0 b      14.00 Gb      14.00 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      20.930ms         1.60%      20.930ms     654.070us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::pow         0.04%     549.420us         0.72%       9.315ms     143.312us      20.767ms         1.58%      20.767ms     319.485us           0 b           0 b      16.25 Gb      16.25 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      20.767ms         1.58%      20.767ms     319.485us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      16.456ms         1.25%      16.456ms     257.120us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.209ms         1.16%      15.209ms     237.641us           0 b           0 b           0 b           0 b            64  \n",
      "                                             aten::mean         0.05%     649.523us         0.35%       4.580ms      70.457us      11.689ms         0.89%      11.689ms     179.836us           0 b           0 b       4.06 Mb       4.06 Mb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      11.689ms         0.89%      11.689ms     179.836us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::neg         0.03%     454.711us         0.33%       4.253ms      66.459us       6.675ms         0.51%       6.675ms     104.301us           0 b           0 b       2.50 Gb       2.50 Gb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.675ms         0.51%       6.675ms     104.301us           0 b           0 b           0 b           0 b            64  \n",
      "                                        aten::embedding         0.00%      12.586us         0.01%     127.763us     127.763us       0.000us         0.00%     711.046us     711.046us           0 b           0 b     128.00 Mb           0 b             1  \n",
      "                                     aten::index_select         0.00%      42.154us         0.01%     104.276us     104.276us     711.046us         0.05%     711.046us     711.046us           0 b           0 b     128.00 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     711.046us         0.05%     711.046us     711.046us           0 b           0 b           0 b           0 b             1  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     465.280us         0.04%     465.280us       2.423us           0 b           0 b           0 b           0 b           192  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     206.688us         0.02%     206.688us       6.459us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     204.672us         0.02%     204.672us       3.149us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.03%     350.560us         0.45%       5.897ms      90.719us     168.899us         0.01%     168.899us       2.598us           0 b           0 b       4.06 Mb       4.06 Mb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     168.899us         0.01%     168.899us       2.598us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::sin         0.02%     248.137us         0.03%     420.963us      13.155us     102.015us         0.01%     102.015us       3.188us           0 b           0 b       8.00 Mb       8.00 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     102.015us         0.01%     102.015us       3.188us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.02%     270.896us         0.18%       2.339ms      73.085us     101.636us         0.01%     101.636us       3.176us           0 b           0 b       8.00 Mb       8.00 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     101.636us         0.01%     101.636us       3.176us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::bmm         0.07%     872.869us         0.33%       4.258ms     133.064us      99.554us         0.01%      99.554us       3.111us           0 b           0 b       4.00 Mb       4.00 Mb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      99.554us         0.01%      99.554us       3.111us           0 b           0 b           0 b           0 b            32  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      18.816us         0.00%      18.816us       9.408us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::all         0.00%      24.806us         0.00%      33.511us      33.511us       6.720us         0.00%       6.720us       6.720us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       6.720us         0.00%       6.720us       6.720us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::sum         0.00%      19.880us         0.67%       8.671ms       8.671ms       6.400us         0.00%       6.400us       6.400us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       6.400us         0.00%       6.400us       6.400us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::eq         0.00%      58.614us         0.05%     686.928us     343.464us       5.792us         0.00%       5.792us       2.896us           0 b           0 b      16.50 Kb      16.50 Kb             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.792us         0.00%       5.792us       2.896us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::arange         0.00%      17.816us         0.00%      56.964us      28.482us       2.048us         0.00%       4.096us       2.048us           0 b           0 b       8.00 Kb           0 b             2  \n",
      "                                       aten::is_nonzero         0.00%      10.145us        61.64%     800.874ms     400.437ms       0.000us         0.00%       3.680us       1.840us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.00%      20.097us        61.64%     800.863ms     400.432ms       0.000us         0.00%       3.680us       1.840us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.01%      68.369us        61.63%     800.843ms     400.422ms       3.680us         0.00%       3.680us       1.840us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       3.680us         0.00%       3.680us       1.840us           0 b           0 b           0 b           0 b             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.048us         0.00%       2.048us       2.048us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::empty         0.05%     607.618us         0.05%     607.618us       3.100us       0.000us         0.00%       0.000us       0.000us     256.50 Kb     256.50 Kb       8.06 Gb       8.06 Gb           196  \n",
      "                                       aten::lift_fresh         0.00%       1.415us         0.00%       1.415us       0.707us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       1.048us         0.00%       1.048us       0.524us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         0.11%       1.434ms         0.11%       1.434ms       5.516us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      28.38 Gb      28.38 Gb           260  \n",
      "                                        cudaMemcpyAsync         0.05%     633.196us         0.05%     633.196us     158.299us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                  cudaStreamSynchronize        61.63%     800.751ms        61.63%     800.751ms     200.188ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us    -256.00 Kb    -256.00 Kb    -175.55 Gb    -175.55 Gb          1585  \n",
      "                                             aten::view         0.02%     253.227us         0.02%     253.227us       0.606us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           418  \n",
      "                                          aten::resize_         0.00%      12.358us         0.00%      12.358us       6.179us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     128.00 Mb     128.00 Mb             2  \n",
      "                                       cudaLaunchKernel        26.31%     341.804ms        26.31%     341.804ms     240.369us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1422  \n",
      "                                        aten::unsqueeze         0.03%     435.100us         0.04%     569.808us       2.532us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           225  \n",
      "                                       aten::as_strided         0.06%     762.563us         0.06%     762.563us       0.551us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1383  \n",
      "                                      aten::result_type         0.00%      26.069us         0.00%      26.069us       0.401us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            65  \n",
      "                                                aten::t         0.04%     458.282us         0.08%       1.085ms       4.843us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           224  \n",
      "                                        aten::transpose         0.07%     876.970us         0.09%       1.190ms       2.324us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           512  \n",
      "                                 cudaDeviceGetAttribute         0.00%      57.313us         0.00%      57.313us       0.597us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            96  \n",
      "                                        cudaMemsetAsync         8.88%     115.388ms         8.88%     115.388ms     600.977us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           192  \n",
      "                                         cuLaunchKernel         0.76%       9.837ms         0.76%       9.837ms     102.468us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            96  \n",
      "                                     aten::_unsafe_view         0.01%     175.842us         0.01%     175.842us       0.550us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           320  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.01%     117.925us         0.01%     117.925us       0.921us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           128  \n",
      "                                            aten::slice         0.07%     868.517us         0.09%       1.106ms       2.295us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           482  \n",
      "                                           aten::expand         0.03%     339.627us         0.03%     413.904us       2.587us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           160  \n",
      "                                       aten::empty_like         0.02%     280.224us         0.05%     620.972us       6.468us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      12.00 Gb           0 b            96  \n",
      "                                  cudaStreamIsCapturing         0.00%      50.726us         0.00%      50.726us       1.585us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            32  \n",
      "                                   cudaFuncSetAttribute         0.49%       6.407ms         0.49%       6.407ms     200.221us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            32  \n",
      "                                           aten::select         0.00%      21.818us         0.00%      24.564us      12.282us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::detach         0.00%       9.801us         0.00%       9.801us       9.801us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize         0.00%      18.417us         0.00%      18.417us      18.417us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.299s\n",
      "Self CUDA time total: 1.312s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.50%       1.383ms        16.68%      46.520ms     181.718us       0.000us         0.00%     221.845ms     866.582us           0 b           0 b       8.94 Gb           0 b           256  \n",
      "                                           aten::linear         0.23%     651.455us        16.65%      46.424ms     207.251us       0.000us         0.00%     221.743ms     989.926us           0 b           0 b       8.94 Gb           0 b           224  \n",
      "                                               aten::mm         1.83%       5.090ms        15.37%      42.861ms     191.344us     221.743ms        75.47%     221.743ms     989.926us           0 b           0 b       8.94 Gb       8.94 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us     122.835ms        41.80%     122.835ms       1.919ms           0 b           0 b           0 b           0 b            64  \n",
      "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      98.444ms        33.50%      98.444ms     615.272us           0 b           0 b           0 b           0 b           160  \n",
      "                                              aten::mul         0.77%       2.138ms         9.55%      26.644ms      91.560us      21.701ms         7.39%      21.701ms      74.573us           0 b           0 b      10.30 Gb      10.30 Gb           291  \n",
      "                                            aten::copy_         0.67%       1.863ms         2.31%       6.452ms      17.971us      18.861ms         6.42%      18.861ms      52.539us           0 b           0 b           0 b           0 b           359  \n",
      "                                               aten::to         0.13%     361.992us         2.57%       7.172ms      18.343us       0.000us         0.00%      11.220ms      28.697us           0 b           0 b       5.19 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.36%       1.010ms         2.44%       6.810ms      29.869us       0.000us         0.00%      11.220ms      49.212us           0 b           0 b       5.19 Gb           0 b           228  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      10.882ms         3.70%      10.882ms      56.383us           0 b           0 b           0 b           0 b           193  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.636ms         2.60%       7.636ms      59.191us           0 b           0 b           0 b           0 b           129  \n",
      "                                            aten::clone         0.10%     273.997us         0.95%       2.637ms      26.913us       0.000us         0.00%       7.419ms      75.708us           0 b           0 b       2.56 Gb           0 b            98  \n",
      "                                              aten::add         0.55%       1.534ms         1.26%       3.526ms      18.176us       6.857ms         2.33%       6.857ms      35.345us           0 b           0 b       2.77 Gb       2.77 Gb           194  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.664ms         1.93%       5.664ms      43.904us           0 b           0 b           0 b           0 b           129  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.605ms         1.91%       5.605ms     175.162us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.551ms         1.89%       5.551ms      57.225us           0 b           0 b           0 b           0 b            97  \n",
      "                     aten::scaled_dot_product_attention         0.26%     718.005us         3.06%       8.538ms     266.799us       0.000us         0.00%       5.394ms     168.574us           0 b        -512 b     875.73 Mb     -16.39 Mb            32  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.207ms         1.77%       5.207ms      80.108us           0 b           0 b           0 b           0 b            65  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.12%     321.807us         0.79%       2.195ms      68.579us       0.000us         0.00%       5.076ms     158.623us         512 b           0 b     872.00 Mb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.21%     589.605us         0.57%       1.588ms      49.631us       5.076ms         1.73%       5.076ms     158.623us         512 b           0 b     872.00 Mb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us       5.076ms         1.73%       5.076ms     158.623us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cat         0.39%       1.091ms         0.80%       2.217ms      23.097us       5.068ms         1.72%       5.068ms      52.790us           0 b           0 b       1.07 Gb       1.07 Gb            96  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       4.886ms         1.66%       4.886ms      76.349us           0 b           0 b           0 b           0 b            64  \n",
      "                                          aten::reshape         0.25%     704.849us         1.08%       3.012ms       8.460us       0.000us         0.00%       4.878ms      13.702us           0 b           0 b       1.70 Gb           0 b           356  \n",
      "                                              aten::pow         0.25%     693.403us         0.50%       1.381ms      21.240us       4.422ms         1.50%       4.422ms      68.025us           0 b           0 b       3.46 Gb       3.46 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.422ms         1.50%       4.422ms      68.025us           0 b           0 b           0 b           0 b            65  \n",
      "                                             aten::silu         0.13%     364.580us         0.21%     573.796us      17.931us       4.415ms         1.50%       4.415ms     137.972us           0 b           0 b       2.98 Gb       2.98 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.415ms         1.50%       4.415ms     137.972us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.625ms         1.23%       3.625ms      56.636us           0 b           0 b           0 b           0 b            64  \n",
      "                                             aten::mean         0.29%     796.578us         0.81%       2.252ms      34.652us       3.406ms         1.16%       3.406ms      52.395us           0 b           0 b     910.00 Kb     910.00 Kb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       3.406ms         1.16%       3.406ms      52.395us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.052ms         1.04%       3.052ms      47.685us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::contiguous         0.02%      43.788us         0.20%     548.630us      17.145us       0.000us         0.00%       2.534ms      79.201us           0 b           0 b     872.00 Mb           0 b            32  \n",
      "                                              aten::neg         0.19%     523.352us         0.48%       1.327ms      20.734us       1.521ms         0.52%       1.521ms      23.760us           0 b           0 b     570.50 Mb     570.50 Mb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.521ms         0.52%       1.521ms      23.760us           0 b           0 b           0 b           0 b            64  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     464.777us         0.16%     464.777us       2.075us           0 b           0 b           0 b           0 b           224  \n",
      "                                              aten::pad         0.05%     135.561us         1.96%       5.455ms     170.464us       0.000us         0.00%     318.438us       9.951us           0 b           0 b      23.84 Mb           0 b            32  \n",
      "                                  aten::constant_pad_nd         0.11%     295.364us         1.91%       5.319ms     166.228us       0.000us         0.00%     318.438us       9.951us           0 b           0 b      23.84 Mb           0 b            32  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     181.538us         0.06%     181.538us       5.673us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     173.921us         0.06%     173.921us       2.676us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.16%     447.380us         0.27%     751.328us      11.559us     157.983us         0.05%     157.983us       2.431us           0 b           0 b     910.00 Kb     910.00 Kb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     157.983us         0.05%     157.983us       2.431us           0 b           0 b           0 b           0 b            65  \n",
      "                                        aten::embedding         0.01%      19.680us         0.06%     177.859us     177.859us       0.000us         0.00%     147.745us     147.745us           0 b           0 b      27.25 Mb           0 b             1  \n",
      "                                     aten::index_select         0.02%      53.958us         0.05%     143.218us     143.218us     147.745us         0.05%     147.745us     147.745us           0 b           0 b      27.25 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     147.745us         0.05%     147.745us     147.745us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::bmm         0.39%       1.087ms         0.48%       1.342ms      41.930us     101.603us         0.03%     101.603us       3.175us           0 b           0 b     880.00 Kb     880.00 Kb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us     101.603us         0.03%     101.603us       3.175us           0 b           0 b           0 b           0 b            32  \n",
      "                                            aten::fill_         0.08%     229.461us         1.47%       4.094ms     124.065us     101.155us         0.03%     101.155us       3.065us           0 b           0 b           0 b           0 b            33  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     101.155us         0.03%     101.155us       3.065us           0 b           0 b           0 b           0 b            33  \n",
      "                                              aten::cos         0.12%     337.228us         0.19%     528.514us      16.516us      93.214us         0.03%      93.214us       2.913us           0 b           0 b       1.70 Mb       1.70 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      93.214us         0.03%      93.214us       2.913us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sin         0.10%     270.310us         0.16%     454.935us      14.217us      90.625us         0.03%      90.625us       2.832us           0 b           0 b       1.70 Mb       1.70 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      90.625us         0.03%      90.625us       2.832us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sum         0.02%      47.826us         0.02%      64.101us      32.050us      12.225us         0.00%      12.225us       6.113us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.225us         0.00%      12.225us       6.113us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::all         0.02%      64.541us         0.03%      94.779us      47.390us      12.160us         0.00%      12.160us       6.080us           0 b           0 b       4.00 Kb       4.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.160us         0.00%      12.160us       6.080us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::arange         0.02%      65.756us         0.08%     227.880us      37.980us       5.793us         0.00%      11.586us       1.931us           0 b           0 b       5.00 Kb           0 b             6  \n",
      "                                               aten::eq         0.04%     114.282us         0.05%     150.544us      37.636us      10.560us         0.00%      10.560us       2.640us           0 b           0 b     747.00 Kb     747.00 Kb             4  \n",
      "                                            aten::index         0.01%      27.068us         0.01%      39.228us      39.228us       9.760us         0.00%       9.760us       9.760us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.760us         0.00%       9.760us       9.760us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.527us         0.00%       6.527us       6.527us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.464us         0.00%       6.464us       6.464us           0 b           0 b           0 b           0 b             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.954us         0.00%       5.954us       2.977us           0 b           0 b           0 b           0 b             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.793us         0.00%       5.793us       1.931us           0 b           0 b           0 b           0 b             3  \n",
      "                                      aten::masked_fill         0.00%       9.840us         0.03%      86.848us      86.848us       0.000us         0.00%       5.696us       5.696us           0 b           0 b     743.00 Kb           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.408us         0.00%       5.408us       2.704us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.376us         0.00%       5.376us       2.688us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.152us         0.00%       5.152us       2.576us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::mul_         0.01%      19.651us         0.01%      29.853us      29.853us       4.896us         0.00%       4.896us       4.896us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       4.896us         0.00%       4.896us       4.896us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.00%      10.827us        60.38%     168.386ms      84.193ms       0.000us         0.00%       3.776us       1.888us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.00%       9.485us        60.37%     168.375ms      84.188ms       0.000us         0.00%       3.776us       1.888us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.01%      34.222us        60.37%     168.366ms      84.183ms       3.776us         0.00%       3.776us       1.888us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       3.776us         0.00%       3.776us       1.888us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::gt         0.01%      26.679us         0.01%      36.516us      36.516us       3.585us         0.00%       3.585us       3.585us           0 b           0 b      12.00 Kb      12.00 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.585us         0.00%       3.585us       3.585us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::triu         0.01%      22.314us         0.01%      34.246us      34.246us       3.584us         0.00%       3.584us       3.584us           0 b           0 b      23.50 Kb      23.50 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       3.584us         0.00%       3.584us       3.584us           0 b           0 b           0 b           0 b             1  \n",
      "                                     aten::masked_fill_         0.01%      16.770us         0.01%      25.633us      25.633us       2.944us         0.00%       2.944us       2.944us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.944us         0.00%       2.944us       2.944us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::sub         0.00%      13.358us         0.01%      19.218us      19.218us       2.272us         0.00%       2.272us       2.272us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.272us         0.00%       2.272us       2.272us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::bitwise_not         0.01%      15.971us         0.01%      24.636us      24.636us       1.984us         0.00%       1.984us       1.984us           0 b           0 b       3.50 Kb       3.50 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.984us         0.00%       1.984us       1.984us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.00%      10.764us         0.02%      51.165us      51.165us       0.000us         0.00%       1.728us       1.728us           0 b           0 b      23.50 Kb           0 b             1  \n",
      "                                            aten::empty         0.35%     983.136us         0.35%     983.136us       3.724us       0.000us         0.00%       0.000us       0.000us      55.00 Kb      55.00 Kb       3.43 Gb       3.43 Gb           264  \n",
      "                                       aten::lift_fresh         0.00%       1.417us         0.00%       1.417us       0.709us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       1.270us         0.00%       1.270us       0.635us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         0.58%       1.618ms         0.58%       1.618ms       7.066us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       5.19 Gb       5.19 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.25%     687.354us         0.25%     687.354us     114.559us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize        60.39%     168.426ms        60.39%     168.426ms      42.107ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us     -54.50 Kb     -54.50 Kb     -38.26 Gb     -38.26 Gb          1639  \n",
      "                                             aten::view         0.11%     319.873us         0.11%     319.873us       0.760us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.02%      41.835us         0.02%      41.835us      10.459us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      27.25 Mb      27.25 Mb             4  \n",
      "                                       cudaLaunchKernel        16.05%      44.757ms        16.05%      44.757ms      27.442us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1631  \n",
      "                                        aten::unsqueeze         0.17%     462.383us         0.22%     603.688us       2.636us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.31%     873.552us         0.31%     873.552us       0.548us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1593  \n",
      "                                            aten::slice         0.47%       1.303ms         0.58%       1.613ms       2.466us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           654  \n",
      "                                           aten::expand         0.15%     419.161us         0.18%     509.157us       2.638us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           193  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 278.884ms\n",
      "Self CUDA time total: 293.835ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.28%       1.475ms        19.26%      99.952ms     390.438us       0.000us         0.00%     403.140ms       1.575ms           0 b           0 b      16.50 Gb           0 b           256  \n",
      "                                           aten::linear         0.14%     704.616us        19.23%      99.840ms     445.715us       0.000us         0.00%     403.045ms       1.799ms           0 b           0 b      16.50 Gb           0 b           224  \n",
      "                                               aten::mm         1.00%       5.179ms        18.49%      95.975ms     428.460us     403.045ms        74.85%     403.045ms       1.799ms           0 b           0 b      16.50 Gb      16.50 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us     321.280ms        59.66%     321.280ms       3.347ms           0 b           0 b           0 b           0 b            96  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      65.344ms        12.13%      65.344ms       1.021ms           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::mul         0.42%       2.173ms         8.74%      45.358ms     155.869us      39.176ms         7.28%      39.176ms     134.626us           0 b           0 b      19.00 Gb      19.00 Gb           291  \n",
      "                                            aten::copy_         0.35%       1.818ms         1.70%       8.849ms      24.649us      33.322ms         6.19%      33.322ms      92.819us           0 b           0 b           0 b           0 b           359  \n",
      "                                               aten::to         0.07%     360.815us         2.03%      10.523ms      26.914us       0.000us         0.00%      19.625ms      50.192us           0 b           0 b       9.57 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.19%       1.008ms         1.96%      10.162ms      44.572us       0.000us         0.00%      19.625ms      86.075us           0 b           0 b       9.57 Gb           0 b           228  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      19.349ms         3.59%      19.349ms     100.255us           0 b           0 b           0 b           0 b           193  \n",
      "                     aten::scaled_dot_product_attention         0.14%     736.797us         0.84%       4.381ms     136.910us       0.000us         0.00%      16.713ms     522.275us           0 b        -512 b       1.58 Gb     -61.24 Mb            32  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.06%     329.919us         0.37%       1.917ms      59.914us       0.000us         0.00%      16.211ms     506.607us         512 b           0 b       1.57 Gb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.11%     571.848us         0.25%       1.274ms      39.819us      16.211ms         3.01%      16.211ms     506.607us         512 b           8 b       1.57 Gb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us      16.211ms         3.01%      16.211ms     506.607us           0 b           0 b           0 b           0 b            32  \n",
      "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      16.005ms         2.97%      16.005ms     250.076us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      13.682ms         2.54%      13.682ms     106.062us           0 b           0 b           0 b           0 b           129  \n",
      "                                            aten::clone         0.06%     287.918us         0.38%       1.962ms      20.025us       0.000us         0.00%      13.337ms     136.096us           0 b           0 b       4.72 Gb           0 b            98  \n",
      "                                              aten::add         0.30%       1.576ms         1.72%       8.933ms      46.047us      12.350ms         2.29%      12.350ms      63.660us           0 b           0 b       5.11 Gb       5.11 Gb           194  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.276ms         1.91%      10.276ms     321.139us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       9.810ms         1.82%       9.810ms     101.129us           0 b           0 b           0 b           0 b            97  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       9.806ms         1.82%       9.806ms      76.017us           0 b           0 b           0 b           0 b           129  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       9.539ms         1.77%       9.539ms     146.759us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::cat         0.22%       1.141ms         2.52%      13.066ms     136.104us       8.905ms         1.65%       8.905ms      92.765us           0 b           0 b       1.97 Gb       1.97 Gb            96  \n",
      "                                          aten::reshape         0.14%     741.054us         0.47%       2.417ms       6.789us       0.000us         0.00%       8.822ms      24.781us           0 b           0 b       3.14 Gb           0 b           356  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       8.724ms         1.62%       8.724ms     136.310us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pow         0.14%     746.759us         0.21%       1.112ms      17.108us       8.370ms         1.55%       8.370ms     128.774us           0 b           0 b       6.38 Gb       6.38 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.370ms         1.55%       8.370ms     128.774us           0 b           0 b           0 b           0 b            65  \n",
      "                                             aten::silu         0.07%     339.470us         1.01%       5.234ms     163.562us       7.988ms         1.48%       7.988ms     249.635us           0 b           0 b       5.50 Gb       5.50 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       7.988ms         1.48%       7.988ms     249.635us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.454ms         1.20%       6.454ms     100.842us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.706ms         1.06%       5.706ms      89.161us           0 b           0 b           0 b           0 b            64  \n",
      "                                             aten::mean         0.16%     838.658us         0.30%       1.536ms      23.635us       5.594ms         1.04%       5.594ms      86.059us           0 b           0 b       1.62 Mb       1.62 Mb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       5.594ms         1.04%       5.594ms      86.059us           0 b           0 b           0 b           0 b            65  \n",
      "                                       aten::contiguous         0.01%      43.459us         0.11%     554.096us      17.316us       0.000us         0.00%       4.501ms     140.662us           0 b           0 b       1.57 Gb           0 b            32  \n",
      "                                              aten::neg         0.11%     580.807us         0.65%       3.357ms      52.457us       2.591ms         0.48%       2.591ms      40.483us           0 b           0 b    1007.62 Mb    1007.62 Mb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.591ms         0.48%       2.591ms      40.483us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pad         0.03%     143.421us         0.30%       1.552ms      48.495us       0.000us         0.00%     501.379us      15.668us           0 b           0 b      81.66 Mb           0 b            32  \n",
      "                                  aten::constant_pad_nd         0.06%     311.730us         0.27%       1.408ms      44.013us       0.000us         0.00%     501.379us      15.668us           0 b           0 b      81.66 Mb           0 b            32  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     416.450us         0.08%     416.450us       2.169us           0 b           0 b           0 b           0 b           192  \n",
      "                                        aten::embedding         0.00%      13.158us         0.02%     119.470us     119.470us       0.000us         0.00%     269.154us     269.154us           0 b           0 b      50.25 Mb           0 b             1  \n",
      "                                     aten::index_select         0.01%      38.836us         0.02%      96.324us      96.324us     269.154us         0.05%     269.154us     269.154us           0 b           0 b      50.25 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     269.154us         0.05%     269.154us     269.154us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     181.664us         0.03%     181.664us       5.677us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     177.827us         0.03%     177.827us       2.736us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.09%     463.568us         0.49%       2.519ms      38.750us     161.828us         0.03%     161.828us       2.490us           0 b           0 b       1.62 Mb       1.62 Mb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     161.828us         0.03%     161.828us       2.490us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::fill_         0.05%     234.992us         0.08%     414.996us      12.576us     151.202us         0.03%     151.202us       4.582us           0 b           0 b           0 b           0 b            33  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     151.202us         0.03%     151.202us       4.582us           0 b           0 b           0 b           0 b            33  \n",
      "                                              aten::bmm         0.19%     991.462us         0.29%       1.519ms      47.469us      94.619us         0.02%      94.619us       2.957us           0 b           0 b       1.58 Mb       1.58 Mb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      94.619us         0.02%      94.619us       2.957us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.06%     323.653us         0.10%     506.948us      15.842us      94.592us         0.02%      94.592us       2.956us           0 b           0 b       3.14 Mb       3.14 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      94.592us         0.02%      94.592us       2.956us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sin         0.05%     279.831us         0.09%     460.137us      14.379us      91.615us         0.02%      91.615us       2.863us           0 b           0 b       3.14 Mb       3.14 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      91.615us         0.02%      91.615us       2.863us           0 b           0 b           0 b           0 b            32  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      14.817us         0.00%      14.817us       7.408us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::eq         0.02%      85.641us         0.02%     108.898us      27.225us      13.504us         0.00%      13.504us       3.376us           0 b           0 b       2.47 Mb       2.47 Mb             4  \n",
      "                                              aten::all         0.01%      35.784us         0.01%      48.343us      24.172us      12.928us         0.00%      12.928us       6.464us           0 b           0 b       7.00 Kb       7.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.928us         0.00%      12.928us       6.464us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::sum         0.02%      91.674us         0.04%     209.983us     104.991us      12.224us         0.00%      12.224us       6.112us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      12.224us         0.00%      12.224us       6.112us           0 b           0 b           0 b           0 b             2  \n",
      "                                           aten::arange         0.01%      51.371us         0.03%     158.895us      26.482us       6.016us         0.00%      12.032us       2.005us           0 b           0 b       9.00 Kb           0 b             6  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      12.000us         0.00%      12.000us      12.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::masked_fill         0.00%       6.836us         0.01%      54.881us      54.881us       0.000us         0.00%      11.743us      11.743us           0 b           0 b       2.47 Mb           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      10.976us         0.00%      10.976us      10.976us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::index         0.01%      30.916us         0.01%      49.061us      49.061us       9.760us         0.00%       9.760us       9.760us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.760us         0.00%       9.760us       9.760us           0 b           0 b           0 b           0 b             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       9.314us         0.00%       9.314us       4.657us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       7.872us         0.00%       7.872us       3.936us           0 b           0 b           0 b           0 b             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       6.016us         0.00%       6.016us       2.005us           0 b           0 b           0 b           0 b             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.632us         0.00%       5.632us       2.816us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::mul_         0.00%      14.235us         0.00%      21.331us      21.331us       5.215us         0.00%       5.215us       5.215us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.215us         0.00%       5.215us       5.215us           0 b           0 b           0 b           0 b             1  \n",
      "                                     aten::masked_fill_         0.00%      12.051us         0.00%      18.151us      18.151us       4.255us         0.00%       4.255us       4.255us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.255us         0.00%       4.255us       4.255us           0 b           0 b           0 b           0 b             1  \n",
      "                                               aten::gt         0.00%      17.409us         0.00%      24.421us      24.421us       3.840us         0.00%       3.840us       3.840us           0 b           0 b      39.50 Kb      39.50 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.840us         0.00%       3.840us       3.840us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::triu         0.00%      13.509us         0.00%      20.692us      20.692us       3.744us         0.00%       3.744us       3.744us           0 b           0 b      79.00 Kb      79.00 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       3.744us         0.00%       3.744us       3.744us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.00%       9.329us        60.43%     313.707ms     156.854ms       0.000us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.00%      12.435us        60.43%     313.698ms     156.849ms       0.000us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.01%      46.540us        60.43%     313.685ms     156.843ms       3.584us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       3.584us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::sub         0.00%      20.546us         0.01%      30.151us      30.151us       2.369us         0.00%       2.369us       2.369us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.369us         0.00%       2.369us       2.369us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::bitwise_not         0.00%      11.087us         0.00%      17.824us      17.824us       2.336us         0.00%       2.336us       2.336us           0 b           0 b       6.50 Kb       6.50 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.336us         0.00%       2.336us       2.336us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.00%       6.116us         0.00%      25.731us      25.731us       0.000us         0.00%       1.920us       1.920us           0 b           0 b      79.00 Kb           0 b             1  \n",
      "                                            aten::empty         0.19%     980.527us         0.19%     980.527us       3.714us       0.000us         0.00%       0.000us       0.000us     100.99 Kb     100.99 Kb       6.36 Gb       6.36 Gb           264  \n",
      "                                       aten::lift_fresh         0.00%       1.248us         0.00%       1.248us       0.624us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       1.000us         0.00%       1.000us       0.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         0.30%       1.548ms         0.30%       1.548ms       6.762us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       9.57 Gb       9.57 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.12%     597.055us         0.12%     597.055us      99.509us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize        60.41%     313.609ms        60.41%     313.609ms      78.402ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us    -100.50 Kb    -100.50 Kb     -70.52 Gb     -70.52 Gb          1638  \n",
      "                                             aten::view         0.06%     327.413us         0.06%     327.413us       0.778us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.00%      22.023us         0.00%      22.023us       5.506us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      50.25 Mb      50.25 Mb             4  \n",
      "                                       cudaLaunchKernel        19.22%      99.751ms        19.22%      99.751ms      61.160us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1631  \n",
      "                                        aten::unsqueeze         0.10%     529.857us         0.13%     696.282us       3.041us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.21%       1.067ms         0.21%       1.067ms       0.670us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1593  \n",
      "                                            aten::slice         0.28%       1.462ms         0.35%       1.829ms       2.797us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           654  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 519.092ms\n",
      "Self CUDA time total: 538.496ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/alkestrup/venv/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for mteb/amazon_massive_intent contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_massive_intent\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         0.85%     940.865us         6.74%       7.467ms      29.166us       0.000us         0.00%      88.664ms     346.345us           0 b           0 b       3.61 Gb           0 b           256  \n",
      "                                           aten::linear         0.42%     467.652us         6.69%       7.410ms      33.082us       0.000us         0.00%      88.576ms     395.428us           0 b           0 b       3.61 Gb           0 b           224  \n",
      "                                               aten::mm         3.02%       3.344ms         4.51%       4.994ms      22.296us      88.576ms        74.51%      88.576ms     395.428us           0 b           0 b       3.61 Gb       3.61 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      70.761ms        59.53%      70.761ms     737.093us           0 b           0 b           0 b           0 b            96  \n",
      "ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      13.609ms        11.45%      13.609ms     212.634us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::mul         1.31%       1.451ms         6.19%       6.858ms      23.567us       8.832ms         7.43%       8.832ms      30.350us           0 b           0 b       4.16 Gb       4.16 Gb           291  \n",
      "                                            aten::copy_         1.05%       1.167ms         4.40%       4.871ms      13.568us       8.121ms         6.83%       8.121ms      22.622us           0 b           0 b           0 b           0 b           359  \n",
      "                                               aten::to         0.25%     272.207us         4.81%       5.321ms      13.610us       0.000us         0.00%       4.843ms      12.387us           0 b           0 b       2.10 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.57%     629.780us         4.56%       5.049ms      22.146us       0.000us         0.00%       4.843ms      21.242us           0 b           0 b       2.10 Gb           0 b           228  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.368ms         3.67%       4.368ms      22.632us           0 b           0 b           0 b           0 b           193  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us       3.935ms         3.31%       3.935ms      61.482us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.274ms         2.75%       3.274ms      25.378us           0 b           0 b           0 b           0 b           129  \n",
      "                                            aten::clone         0.18%     196.139us         2.92%       3.238ms      33.041us       0.000us         0.00%       3.100ms      31.628us           0 b           0 b       1.03 Gb           0 b            98  \n",
      "                                              aten::add         0.89%     990.927us         1.96%       2.171ms      11.191us       2.785ms         2.34%       2.785ms      14.355us           0 b           0 b       1.12 Gb       1.12 Gb           194  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.591ms         2.18%       2.591ms      20.082us           0 b           0 b           0 b           0 b           129  \n",
      "                     aten::scaled_dot_product_attention         0.45%     501.191us         2.83%       3.129ms      97.793us       0.000us         0.00%       2.370ms      74.049us           0 b        -512 b     352.90 Mb      -2.32 Mb            32  \n",
      "                                              aten::cat         0.67%     741.247us         1.04%       1.155ms      12.031us       2.261ms         1.90%       2.261ms      23.548us           0 b           0 b     440.69 Mb     440.69 Mb            96  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.249ms         1.89%       2.249ms      23.190us           0 b           0 b           0 b           0 b            97  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.240ms         1.88%       2.240ms      34.455us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.218ms         1.87%       2.218ms      69.322us           0 b           0 b           0 b           0 b            32  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.24%     265.972us         1.27%       1.402ms      43.825us       0.000us         0.00%       2.124ms      66.380us         512 b           0 b     352.00 Mb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.36%     400.832us         0.79%     873.016us      27.282us       2.124ms         1.79%       2.124ms      66.380us         512 b          40 b     352.00 Mb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us       2.124ms         1.79%       2.124ms      66.380us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.098ms         1.77%       2.098ms      32.788us           0 b           0 b           0 b           0 b            64  \n",
      "                                          aten::reshape         0.47%     517.008us         3.19%       3.531ms       9.918us       0.000us         0.00%       2.020ms       5.675us           0 b           0 b     704.75 Mb           0 b           356  \n",
      "                                             aten::silu         0.21%     229.249us         0.34%     371.885us      11.621us       1.788ms         1.50%       1.788ms      55.888us           0 b           0 b       1.20 Gb       1.20 Gb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.788ms         1.50%       1.788ms      55.888us           0 b           0 b           0 b           0 b            32  \n",
      "                                             aten::mean         0.52%     580.171us         0.74%     823.339us      12.667us       1.742ms         1.47%       1.742ms      26.804us           0 b           0 b     357.50 Kb     357.50 Kb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.742ms         1.47%       1.742ms      26.804us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.497ms         1.26%       1.497ms      23.398us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pow         0.45%     498.833us         0.68%     757.506us      11.654us       1.456ms         1.23%       1.456ms      22.405us           0 b           0 b       1.40 Gb       1.40 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.456ms         1.23%       1.456ms      22.405us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.130ms         0.95%       1.130ms      17.653us           0 b           0 b           0 b           0 b            64  \n",
      "                                       aten::contiguous         0.03%      28.104us         0.36%     394.807us      12.338us       0.000us         0.00%       1.073ms      33.544us           0 b           0 b     352.00 Mb           0 b            32  \n",
      "                                              aten::neg         0.32%     350.356us         0.65%     715.655us      11.182us     590.178us         0.50%     590.178us       9.222us           0 b           0 b     220.00 Mb     220.00 Mb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     590.178us         0.50%     590.178us       9.222us           0 b           0 b           0 b           0 b            64  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     271.494us         0.23%     271.494us       1.697us           0 b           0 b           0 b           0 b           160  \n",
      "                                              aten::pad         0.11%     124.594us         0.97%       1.079ms      33.732us       0.000us         0.00%     245.408us       7.669us           0 b           0 b       4.12 Mb           0 b            32  \n",
      "                                  aten::constant_pad_nd         0.17%     189.226us         0.86%     954.832us      29.838us       0.000us         0.00%     245.408us       7.669us           0 b           0 b       4.12 Mb           0 b            32  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     162.208us         0.14%     162.208us       5.069us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     151.424us         0.13%     151.424us       2.330us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.27%     299.138us         0.62%     682.499us      10.500us     137.858us         0.12%     137.858us       2.121us           0 b           0 b     357.50 Kb     357.50 Kb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     137.858us         0.12%     137.858us       2.121us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::bmm         0.60%     659.847us         0.80%     887.339us      27.729us      88.578us         0.07%      88.578us       2.768us           0 b           0 b     352.00 Kb     352.00 Kb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      88.578us         0.07%      88.578us       2.768us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.19%     207.471us         0.33%     370.880us      11.590us      86.814us         0.07%      86.814us       2.713us           0 b           0 b     704.00 Kb     704.00 Kb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      86.814us         0.07%      86.814us       2.713us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sin         0.17%     186.708us         0.30%     337.585us      10.550us      84.675us         0.07%      84.675us       2.646us           0 b           0 b     704.00 Kb     704.00 Kb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      84.675us         0.07%      84.675us       2.646us           0 b           0 b           0 b           0 b            32  \n",
      "                                            aten::fill_         0.14%     156.417us         0.27%     298.467us       9.044us      70.914us         0.06%      70.914us       2.149us           0 b           0 b           0 b           0 b            33  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      70.914us         0.06%      70.914us       2.149us           0 b           0 b           0 b           0 b            33  \n",
      "                                        aten::embedding         0.01%      11.196us         0.10%     115.102us     115.102us       0.000us         0.00%      61.153us      61.153us           0 b           0 b      11.00 Mb           0 b             1  \n",
      "                                     aten::index_select         0.04%      39.061us         0.09%      94.621us      94.621us      61.153us         0.05%      61.153us      61.153us           0 b           0 b      11.00 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      61.153us         0.05%      61.153us      61.153us           0 b           0 b           0 b           0 b             1  \n",
      "                                           aten::arange         0.04%      44.795us         0.12%     134.601us      22.433us       5.312us         0.00%      10.624us       1.771us           0 b           0 b       3.00 Kb           0 b             6  \n",
      "                                              aten::sum         0.10%     107.716us         0.12%     128.894us      64.447us      10.208us         0.01%      10.208us       5.104us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      10.208us         0.01%      10.208us       5.104us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::all         0.03%      32.130us         0.04%      43.072us      21.536us       9.664us         0.01%       9.664us       4.832us           0 b           0 b       2.00 Kb       2.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       9.664us         0.01%       9.664us       4.832us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::eq         0.06%      67.704us         0.08%      90.139us      22.535us       8.736us         0.01%       8.736us       2.184us           0 b           0 b     123.00 Kb     123.00 Kb             4  \n",
      "                                            aten::index         0.03%      27.995us         0.04%      43.584us      43.584us       8.640us         0.01%       8.640us       8.640us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.640us         0.01%       8.640us       8.640us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.175us         0.01%       6.175us       6.175us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.112us         0.01%       6.112us       6.112us           0 b           0 b           0 b           0 b             1  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.312us         0.00%       5.312us       1.771us           0 b           0 b           0 b           0 b             3  \n",
      "                                             aten::mul_         0.01%      13.256us         0.02%      20.271us      20.271us       4.928us         0.00%       4.928us       4.928us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       4.928us         0.00%       4.928us       4.928us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.576us         0.00%       4.576us       2.288us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::masked_fill         0.01%       6.515us         0.04%      48.066us      48.066us       0.000us         0.00%       4.449us       4.449us           0 b           0 b     121.00 Kb           0 b             1  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       4.321us         0.00%       4.321us       2.160us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.160us         0.00%       4.160us       2.080us           0 b           0 b           0 b           0 b             2  \n",
      "                                       aten::is_nonzero         0.01%       8.296us        65.98%      73.051ms      36.526ms       0.000us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.01%       8.152us        65.97%      73.043ms      36.522ms       0.000us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.03%      32.203us        65.96%      73.035ms      36.518ms       3.584us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       3.584us         0.00%       3.584us       1.792us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::gt         0.01%      15.497us         0.02%      22.102us      22.102us       3.424us         0.00%       3.424us       3.424us           0 b           0 b       2.00 Kb       2.00 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.424us         0.00%       3.424us       3.424us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::triu         0.01%      13.274us         0.02%      19.665us      19.665us       3.392us         0.00%       3.392us       3.392us           0 b           0 b       4.00 Kb       4.00 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       3.392us         0.00%       3.392us       3.392us           0 b           0 b           0 b           0 b             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.232us         0.00%       3.232us       1.616us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::bitwise_not         0.01%      10.220us         0.01%      16.342us      16.342us       2.336us         0.00%       2.336us       2.336us           0 b           0 b       1.50 Kb       1.50 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.336us         0.00%       2.336us       2.336us           0 b           0 b           0 b           0 b             1  \n",
      "                                     aten::masked_fill_         0.01%      11.989us         0.02%      17.742us      17.742us       2.240us         0.00%       2.240us       2.240us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.240us         0.00%       2.240us       2.240us           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::sub         0.01%      15.931us         0.02%      23.479us      23.479us       2.080us         0.00%       2.080us       2.080us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.080us         0.00%       2.080us       2.080us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.01%       6.287us         0.02%      24.728us      24.728us       0.000us         0.00%       1.856us       1.856us           0 b           0 b       4.00 Kb           0 b             1  \n",
      "                                            aten::empty         0.63%     699.591us         0.63%     699.591us       2.650us       0.000us         0.00%       0.000us       0.000us      22.46 Kb      22.46 Kb       1.38 Gb       1.38 Gb           264  \n",
      "                                       aten::lift_fresh         0.00%       0.982us         0.00%       0.982us       0.491us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       1.197us         0.00%       1.197us       0.599us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         2.12%       2.347ms         2.12%       2.347ms      10.251us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       2.10 Gb       2.10 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.52%     572.623us         0.52%     572.623us      95.437us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize        65.91%      72.974ms        65.91%      72.974ms      18.243ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us     -22.00 Kb     -22.00 Kb     -15.44 Gb     -15.44 Gb          1641  \n",
      "                                             aten::view         0.20%     219.681us         0.20%     219.681us       0.522us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.02%      19.990us         0.02%      19.990us       4.998us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      11.00 Mb      11.00 Mb             4  \n",
      "                                       cudaLaunchKernel        11.82%      13.083ms        11.82%      13.083ms       8.349us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1567  \n",
      "                                        aten::unsqueeze         0.29%     325.481us         0.40%     441.617us       1.928us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.59%     653.430us         0.59%     653.430us       0.410us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1593  \n",
      "                                            aten::slice         0.88%     970.869us         1.08%       1.195ms       1.827us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           654  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 110.720ms\n",
      "Self CUDA time total: 118.870ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Meta-Llama-3-8B-Instruct:   0%|          | 0/1 [00:36<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::matmul         1.28%       1.085ms        15.85%      13.485ms      52.677us       0.000us         0.00%      65.930ms     257.537us           0 b           0 b       2.63 Gb           0 b           256  \n",
      "                                           aten::linear         0.60%     512.489us        15.75%      13.402ms      59.832us       0.000us         0.00%      65.841ms     293.935us           0 b           0 b       2.62 Gb           0 b           224  \n",
      "                                               aten::mm         5.11%       4.347ms        12.69%      10.798ms      48.205us      65.841ms        74.89%      65.841ms     293.935us           0 b           0 b       2.62 Gb       2.62 Gb           224  \n",
      "ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      35.188ms        40.02%      35.188ms     549.810us           0 b           0 b           0 b           0 b            64  \n",
      "ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      16.803ms        19.11%      16.803ms     525.082us           0 b           0 b           0 b           0 b            32  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816...         0.00%       0.000us         0.00%       0.000us       0.000us      10.369ms        11.79%      10.369ms     162.012us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::mul         1.77%       1.510ms         2.92%       2.488ms       8.551us       6.352ms         7.22%       6.352ms      21.827us           0 b           0 b       3.02 Gb       3.02 Gb           291  \n",
      "                                            aten::copy_         1.33%       1.130ms         3.36%       2.857ms       8.738us       5.428ms         6.17%       5.428ms      16.599us           0 b           0 b           0 b           0 b           327  \n",
      "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize96x128...         0.00%       0.000us         0.00%       0.000us       0.000us       3.221ms         3.66%       3.221ms      50.324us           0 b           0 b           0 b           0 b            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.120ms         3.55%       3.120ms      16.165us           0 b           0 b           0 b           0 b           193  \n",
      "                                               aten::to         0.42%     354.209us         6.74%       5.739ms      14.677us       0.000us         0.00%       3.115ms       7.966us           0 b           0 b       1.52 Gb           0 b           391  \n",
      "                                         aten::_to_copy         0.76%     650.531us         6.33%       5.385ms      23.617us       0.000us         0.00%       3.115ms      13.660us           0 b           0 b       1.52 Gb           0 b           228  \n",
      "                                            aten::clone         0.28%     236.191us         1.74%       1.483ms      15.133us       0.000us         0.00%       2.311ms      23.585us           0 b           0 b     768.12 Mb           0 b            98  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.309ms         2.63%       2.309ms      23.807us           0 b           0 b           0 b           0 b            97  \n",
      "                                              aten::add         1.21%       1.029ms         2.03%       1.729ms       8.913us       2.023ms         2.30%       2.023ms      10.427us           0 b           0 b     832.32 Mb     832.32 Mb           194  \n",
      "                     aten::scaled_dot_product_attention         0.41%     349.794us         2.08%       1.772ms      55.367us       0.000us         0.00%       1.895ms      59.208us          32 b        -448 b     256.00 Mb           0 b            32  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.26%     220.608us         1.60%       1.363ms      42.584us       0.000us         0.00%       1.895ms      59.208us         512 b           0 b     256.00 Mb           0 b            32  \n",
      "                     aten::_efficient_attention_forward         0.56%     479.253us         1.14%     969.078us      30.284us       1.895ms         2.15%       1.895ms      59.208us         512 b          16 b     256.00 Mb           0 b            32  \n",
      "fmha_cutlassF_f16_aligned_64x128_rf_sm80(PyTorchMemE...         0.00%       0.000us         0.00%       0.000us       0.000us       1.895ms         2.15%       1.895ms      59.208us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.749ms         1.99%       1.749ms      13.557us           0 b           0 b           0 b           0 b           129  \n",
      "                                              aten::cat         0.92%     783.389us         1.41%       1.197ms      12.471us       1.723ms         1.96%       1.723ms      17.949us           0 b           0 b     320.50 Mb     320.50 Mb            96  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.614ms         1.84%       1.614ms      24.824us           0 b           0 b           0 b           0 b            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.612ms         1.83%       1.612ms      50.372us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.545ms         1.76%       1.545ms      24.146us           0 b           0 b           0 b           0 b            64  \n",
      "                                             aten::mean         0.69%     590.216us         0.97%     826.981us      12.723us       1.535ms         1.75%       1.535ms      23.621us           0 b           0 b     260.00 Kb     260.00 Kb            65  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.535ms         1.75%       1.535ms      23.621us           0 b           0 b           0 b           0 b            65  \n",
      "                                          aten::reshape         0.65%     553.350us         2.09%       1.778ms       4.994us       0.000us         0.00%       1.507ms       4.232us           0 b           0 b     512.00 Mb           0 b           356  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.363ms         1.55%       1.363ms      14.048us           0 b           0 b           0 b           0 b            97  \n",
      "                                             aten::silu         0.27%     228.703us         0.44%     374.601us      11.706us       1.302ms         1.48%       1.302ms      40.684us           0 b           0 b     896.00 Mb     896.00 Mb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.302ms         1.48%       1.302ms      40.684us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.116ms         1.27%       1.116ms      17.444us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::pow         0.63%     537.991us         0.95%     805.683us      12.395us     850.948us         0.97%     850.948us      13.092us           0 b           0 b       1.02 Gb       1.02 Gb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     850.948us         0.97%     850.948us      13.092us           0 b           0 b           0 b           0 b            65  \n",
      "                                       aten::contiguous         0.03%      28.514us         0.50%     421.500us      13.172us       0.000us         0.00%     799.079us      24.971us           0 b           0 b     256.00 Mb           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     759.145us         0.86%     759.145us      11.862us           0 b           0 b           0 b           0 b            64  \n",
      "                                              aten::neg         0.45%     383.180us         0.74%     632.212us       9.878us     471.774us         0.54%     471.774us       7.371us           0 b           0 b     160.00 Mb     160.00 Mb            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     471.774us         0.54%     471.774us       7.371us           0 b           0 b           0 b           0 b            64  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     261.443us         0.30%     261.443us       1.634us           0 b           0 b           0 b           0 b           160  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     177.731us         0.20%     177.731us       5.554us           0 b           0 b           0 b           0 b            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     141.377us         0.16%     141.377us       2.175us           0 b           0 b           0 b           0 b            65  \n",
      "                                            aten::rsqrt         0.39%     327.903us         0.67%     573.695us       8.826us     135.492us         0.15%     135.492us       2.084us           0 b           0 b     260.00 Kb     260.00 Kb            65  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     135.492us         0.15%     135.492us       2.084us           0 b           0 b           0 b           0 b            65  \n",
      "                                              aten::bmm         0.80%     683.932us         1.00%     849.782us      26.556us      88.159us         0.10%      88.159us       2.755us           0 b           0 b     256.00 Kb     256.00 Kb            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      88.159us         0.10%      88.159us       2.755us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::cos         0.25%     215.888us         0.41%     350.716us      10.960us      85.026us         0.10%      85.026us       2.657us           0 b           0 b     512.00 Kb     512.00 Kb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      85.026us         0.10%      85.026us       2.657us           0 b           0 b           0 b           0 b            32  \n",
      "                                              aten::sin         0.21%     178.145us         0.37%     312.002us       9.750us      82.433us         0.09%      82.433us       2.576us           0 b           0 b     512.00 Kb     512.00 Kb            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      82.433us         0.09%      82.433us       2.576us           0 b           0 b           0 b           0 b            32  \n",
      "                                        aten::embedding         0.02%      13.209us         0.15%     123.759us     123.759us       0.000us         0.00%      45.632us      45.632us           0 b           0 b       8.00 Mb           0 b             1  \n",
      "                                     aten::index_select         0.05%      41.775us         0.12%     100.807us     100.807us      45.632us         0.05%      45.632us      45.632us           0 b           0 b       8.00 Mb           0 b             1  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      45.632us         0.05%      45.632us      45.632us           0 b           0 b           0 b           0 b             1  \n",
      "                                           aten::arange         0.05%      43.600us         0.16%     138.114us      23.019us       5.378us         0.01%      10.756us       1.793us           0 b           0 b       3.00 Kb           0 b             6  \n",
      "                                              aten::sum         0.04%      36.603us         0.10%      84.655us      42.327us       9.792us         0.01%       9.792us       4.896us           0 b           0 b       1.00 Kb       1.00 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       9.792us         0.01%       9.792us       4.896us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::all         0.04%      33.040us         0.06%      52.667us      26.333us       9.248us         0.01%       9.248us       4.624us           0 b           0 b       1.50 Kb       1.50 Kb             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       9.248us         0.01%       9.248us       4.624us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::eq         0.09%      75.164us         0.12%      99.733us      24.933us       8.512us         0.01%       8.512us       2.128us           0 b           0 b      65.50 Kb      65.50 Kb             4  \n",
      "                                            aten::index         0.03%      29.375us         0.05%      42.658us      42.658us       8.384us         0.01%       8.384us       8.384us           0 b           0 b     256.00 Kb     256.00 Kb             1  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.384us         0.01%       8.384us       8.384us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.208us         0.01%       6.208us       6.208us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.888us         0.01%       5.888us       5.888us           0 b           0 b           0 b           0 b             1  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.378us         0.01%       5.378us       1.793us           0 b           0 b           0 b           0 b             3  \n",
      "                                             aten::mul_         0.02%      14.354us         0.03%      21.743us      21.743us       4.992us         0.01%       4.992us       4.992us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       4.992us         0.01%       4.992us       4.992us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.575us         0.01%       4.575us       2.288us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       4.096us         0.00%       4.096us       2.048us           0 b           0 b           0 b           0 b             2  \n",
      "                                      aten::masked_fill         0.01%       6.987us         0.06%      51.160us      51.160us       0.000us         0.00%       4.096us       4.096us           0 b           0 b      64.00 Kb           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.937us         0.00%       3.937us       1.968us           0 b           0 b           0 b           0 b             2  \n",
      "                                               aten::gt         0.02%      16.589us         0.03%      24.154us      24.154us       3.680us         0.00%       3.680us       3.680us           0 b           0 b       1.00 Kb       1.00 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.680us         0.00%       3.680us       3.680us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::is_nonzero         0.01%       8.990us        57.53%      48.956ms      24.478ms       0.000us         0.00%       3.424us       1.712us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::item         0.01%       7.832us        57.52%      48.947ms      24.473ms       0.000us         0.00%       3.424us       1.712us           0 b           0 b           0 b           0 b             2  \n",
      "                              aten::_local_scalar_dense         0.03%      29.207us        57.51%      48.939ms      24.469ms       3.424us         0.00%       3.424us       1.712us           0 b           0 b           0 b           0 b             2  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       3.424us         0.00%       3.424us       1.712us           0 b           0 b           0 b           0 b             2  \n",
      "                                             aten::triu         0.02%      13.369us         0.02%      20.118us      20.118us       3.392us         0.00%       3.392us       3.392us           0 b           0 b       2.00 Kb       2.00 Kb             1  \n",
      "void at::native::triu_tril_kernel<c10::Half, int, tr...         0.00%       0.000us         0.00%       0.000us       0.000us       3.392us         0.00%       3.392us       3.392us           0 b           0 b           0 b           0 b             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.008us         0.00%       3.008us       1.504us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::sub         0.02%      16.331us         0.03%      23.119us      23.119us       2.176us         0.00%       2.176us       2.176us           0 b           0 b         512 b         512 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.176us         0.00%       2.176us       2.176us           0 b           0 b           0 b           0 b             1  \n",
      "                                     aten::masked_fill_         0.01%      12.515us         0.02%      18.772us      18.772us       2.048us         0.00%       2.048us       2.048us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.048us         0.00%       2.048us       2.048us           0 b           0 b           0 b           0 b             1  \n",
      "                                      aten::bitwise_not         0.01%      11.538us         0.02%      18.540us      18.540us       1.920us         0.00%       1.920us       1.920us           0 b           0 b       1.00 Kb       1.00 Kb             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.920us         0.00%       1.920us       1.920us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::full         0.01%       7.092us         0.03%      27.562us      27.562us       0.000us         0.00%       1.728us       1.728us           0 b           0 b       2.00 Kb           0 b             1  \n",
      "                                            aten::fill_         0.01%       9.706us         0.02%      17.511us      17.511us       1.728us         0.00%       1.728us       1.728us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.728us         0.00%       1.728us       1.728us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::empty         0.70%     595.822us         0.70%     595.822us       2.568us       0.000us         0.00%       0.000us       0.000us      16.48 Kb      16.48 Kb       1.00 Gb       1.00 Gb           232  \n",
      "                                       aten::lift_fresh         0.00%       1.044us         0.00%       1.044us       0.522us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                          aten::detach_         0.00%       0.842us         0.00%       0.842us       0.421us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                    aten::empty_strided         3.06%       2.603ms         3.06%       2.603ms      11.365us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.52 Gb       1.52 Gb           229  \n",
      "                                        cudaMemcpyAsync         0.67%     568.264us         0.67%     568.264us      94.711us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             6  \n",
      "                                  cudaStreamSynchronize        57.43%      48.876ms        57.43%      48.876ms      12.219ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             4  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us     -16.03 Kb     -16.03 Kb     -11.22 Gb     -11.22 Gb          1638  \n",
      "                                             aten::view         0.27%     227.274us         0.27%     227.274us       0.540us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           421  \n",
      "                                          aten::resize_         0.02%      20.877us         0.02%      20.877us       5.219us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       8.00 Mb       8.00 Mb             4  \n",
      "                                       cudaLaunchKernel         6.84%       5.821ms         6.84%       5.821ms       3.873us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1503  \n",
      "                                        aten::unsqueeze         0.45%     380.751us         0.58%     489.675us       2.138us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           229  \n",
      "                                       aten::as_strided         0.79%     670.617us         0.79%     670.617us       0.439us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1529  \n",
      "                                            aten::slice         0.99%     846.538us         1.26%       1.072ms       1.817us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           590  \n",
      "                                           aten::expand         0.39%     332.046us         0.49%     413.899us       2.145us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           193  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 85.099ms\n",
      "Self CUDA time total: 87.923ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [32, 476]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 254\u001b[0m\n\u001b[1;32m    252\u001b[0m models \u001b[38;5;241m=\u001b[39m [seb\u001b[38;5;241m.\u001b[39mget_model(model_name)]\n\u001b[1;32m    253\u001b[0m benchmark \u001b[38;5;241m=\u001b[39m seb\u001b[38;5;241m.\u001b[39mBenchmark(languages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mda\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 254\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m#Save pickle\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEB_eval_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/seb/benchmark.py:227\u001b[0m, in \u001b[0;36mBenchmark.evaluate_models\u001b[0;34m(self, models, use_cache, run_model, raise_errors, cache_dir, verbose)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    225\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    226\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/seb/benchmark.py:180\u001b[0m, in \u001b[0;36mBenchmark.evaluate_model\u001b[0;34m(self, model, use_cache, run_model, raise_errors, cache_dir, verbose)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    179\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m     task_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     task_results\u001b[38;5;241m.\u001b[39mappend(task_result)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BenchmarkResults(meta\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmeta, task_results\u001b[38;5;241m=\u001b[39mtask_results)\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/seb/benchmark.py:90\u001b[0m, in \u001b[0;36mrun_task\u001b[0;34m(task, model, use_cache, run_model, raise_errors, cache_dir)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCache for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSet run_model=True to run the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WarningIgnoreContextManager():\n\u001b[0;32m---> 90\u001b[0m     task_result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m task_result\u001b[38;5;241m.\u001b[39mto_disk(cache_path)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m task_result\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/seb/interfaces/mteb_task.py:125\u001b[0m, in \u001b[0;36mMTEBTask.evaluate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    123\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmteb_task\u001b[38;5;241m.\u001b[39mevaluate(model, split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Resetting encode to original\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     model\u001b[38;5;241m.\u001b[39mencode \u001b[38;5;241m=\u001b[39m original_encode\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/seb/interfaces/mteb_task.py:123\u001b[0m, in \u001b[0;36mMTEBTask.evaluate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     model\u001b[38;5;241m.\u001b[39mencode \u001b[38;5;241m=\u001b[39m partial(model\u001b[38;5;241m.\u001b[39mencode, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmteb_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskClassification.py:51\u001b[0m, in \u001b[0;36mAbsTaskClassification.evaluate\u001b[0;34m(self, model, eval_split, train_split, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m     50\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, language: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Running...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m         scores[lang] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_monolingual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_main_score(scores[lang])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/mteb/abstasks/AbsTaskClassification.py:90\u001b[0m, in \u001b[0;36mAbsTaskClassification._evaluate_monolingual\u001b[0;34m(self, model, dataset, eval_split, train_split, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m     scores_exp, test_cache \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(scores_exp)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_experiments \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/mteb/evaluation/evaluators/ClassificationEvaluator.py:219\u001b[0m, in \u001b[0;36mlogRegClassificationEvaluator.__call__\u001b[0;34m(self, model, test_cache)\u001b[0m\n\u001b[1;32m    217\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m test_cache\n\u001b[1;32m    218\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting logistic regression classifier...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 219\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    221\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1320\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1320\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/alkestrup/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [32, 476]"
     ]
    }
   ],
   "source": [
    "from collections.abc import Iterable, Sequence\n",
    "from datetime import date\n",
    "from functools import partial\n",
    "from itertools import islice\n",
    "from typing import Any, Literal, Optional, TypeVar\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer, BatchEncoding\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "\n",
    "import seb\n",
    "from seb.interfaces.model import Encoder, LazyLoadEncoder, ModelMeta, SebModel\n",
    "from seb.interfaces.task import Task\n",
    "from seb.registries import models\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "#import logging\n",
    "#logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "EncodeTypes = Literal[\"query\", \"passage\"]\n",
    "\n",
    "\n",
    "def batched(iterable: Iterable[T], n: int) -> Iterable[tuple[T, ...]]:\n",
    "    # batched('ABCDEFG', 3) --> ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "    it = iter(iterable)\n",
    "    while batch := tuple(islice(it, n)):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def batch_to_device(batch_data: dict[str, torch.Tensor], device: str = \"cuda\") -> dict[str, torch.Tensor]:\n",
    "    return {key: data.to(device) for key, data in batch_data.items()}\n",
    "\n",
    "\n",
    "def task_to_instruction(task: Task) -> str:\n",
    "    if task.task_type in [\"STS\"]:\n",
    "        return \"Retrieve semantically similar text\"\n",
    "    if task.task_type in [\"Summarization\"]:\n",
    "        return \"Given a news summary, retrieve other semantically similar summaries\"\n",
    "    if task.task_type in [\"BitextMining\"]:\n",
    "        task_name_to_instruct: dict[str, str] = {\n",
    "            \"Bornholm Parallel\": \"Retrieve parallel sentences in Danish and Bornholmsk\",\n",
    "            \"Norwegian courts\": \"Retrieve parallel sentences in Norwegian Bokml and Nynorsk\",\n",
    "        }\n",
    "        default_instruction = \"Retrieve parallel sentences.\"\n",
    "        return task_name_to_instruct.get(task.name, default_instruction)\n",
    "    if task.task_type in [\"Classification\"]:\n",
    "        task_name_to_instruct: dict[str, str] = {\n",
    "            \"Angry Tweets\": \"Classify Danish tweets by sentiment. (positive, negative, neutral)\",\n",
    "            \"DKHate\": \"Classify Danish tweets based on offensiveness (offensive, not offensive)\",\n",
    "            \"Da Political Comments\": \"Classify Danish political comments for sentiment\",\n",
    "            \"DaLAJ\": \"Classify texts based on linguistic acceptability in Swedish\",\n",
    "            \"LCC\": \"Classify texts based on sentiment\",\n",
    "            \"Language Identification\": \"Classify texts based on language\",\n",
    "            \"Massive Intent\": \"Given a user utterance as query, find the user intents\",\n",
    "            \"Massive Scenario\": \"Given a user utterance as query, find the user scenarios\",\n",
    "            \"NoReC\": \"Classify Norwegian reviews by sentiment\",\n",
    "            \"SweReC\": \"Classify Swedish reviews by sentiment\",\n",
    "            \"Norwegian parliament\": \"Classify parliament speeches in Norwegian based on political affiliation\",\n",
    "            \"ScaLA\": \"Classify passages in Scandinavian Languages based on linguistic acceptability\",\n",
    "        }\n",
    "        default_instruction = \"Classify user passages\"\n",
    "        return task_name_to_instruct.get(task.name, default_instruction)\n",
    "    if task.task_type in [\"Clustering\"]:\n",
    "        task_name_to_instruct: dict[str, str] = {\n",
    "            \"ArxivClusteringP2P\": \"Identify the main and secondary category of Arxiv papers based on the titles and abstracts\",\n",
    "            \"VG Clustering\": \"Identify the categories (e.g. sports) of given articles in Norwegian\",\n",
    "            \"SNL Clustering\": \"Identify categories in a Norwegian lexicon\",\n",
    "            \"SwednClustering\": \"Identify news categories in Swedish passages\",\n",
    "        }\n",
    "        default_instruction = \"Identify categories in user passages\"\n",
    "        return task_name_to_instruct.get(task.name, default_instruction)\n",
    "    if task.task_type in [\"Reranking\"]:\n",
    "        return \"Retrieve semantically similar passages.\"\n",
    "    if task.task_type in [\"Retrieval\"]:\n",
    "        task_name_to_instruct: dict[str, str] = {\n",
    "            \"Twitterhjerne\": \"Retrieve answers to questions asked in Danish tweets\",\n",
    "            \"SwednRetrieval\": \"Given a Swedish news headline retrieve summaries or news articles\",\n",
    "            \"TV2Nord Retrieval\": \"Given a summary of a Danish news article retrieve the corresponding news article\",\n",
    "            \"DanFEVER\": \"Given a claim in Danish, retrieve documents that support the claim\",\n",
    "            \"SNL Retrieval\": \"Given a lexicon headline in Norwegian, retrieve its article\",\n",
    "            \"NorQuad\": \"Given a question in Norwegian, retrieve the answer from Wikipedia articles\",\n",
    "            \"SweFAQ\": \"Retrieve answers given questions in Swedish\",\n",
    "            \"ArguAna\": \"Given a claim, find documents that refute the claim\",\n",
    "            \"ClimateFEVER\": \"Given a claim about climate change, retrieve documents that support or refute the claim\",\n",
    "        }\n",
    "        default_instruction = \"Retrieve text based on user query.\"\n",
    "        return task_name_to_instruct.get(task.name, default_instruction)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "class E5Instruct(Encoder):\n",
    "    def __init__(self, model_name: str, max_length: int, max_batch_size: Optional[int] = None, **kwargs: Any):\n",
    "        #logger.info(\"Started loading e5 instruct model\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model = AutoModel.from_pretrained(model_name, **kwargs)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "        self.max_length = max_length\n",
    "        self.max_batch_size = max_batch_size\n",
    "        \n",
    "\n",
    "    def preprocess(self, sentences: Sequence[str], instruction: str, encode_type: EncodeTypes) -> BatchEncoding:\n",
    "        if encode_type == \"query\":\n",
    "            sentences = [f\"Instruction: {instruction}\\nQuery: {sentence}\" for sentence in sentences]\n",
    "\n",
    "        batch_dict = self.tokenizer(\n",
    "            sentences,  # type: ignore\n",
    "            max_length=512,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return batch_dict.to(self.model.device)\n",
    "\n",
    "    def get_embedding_from_output(self, output: ModelOutput, batch_dict: BatchEncoding) -> torch.Tensor:\n",
    "        return self.average_pool(output.last_hidden_state, batch_dict[\"attention_mask\"])  # type: ignore\n",
    "\n",
    "    @staticmethod\n",
    "    def average_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        sentences: list[str],\n",
    "        *,\n",
    "        task: Optional[Task] = None,\n",
    "        batch_size: int = 128,\n",
    "        encode_type: EncodeTypes = \"query\",\n",
    "        **kwargs: Any,  # noqa\n",
    "    ) -> np.ndarray:\n",
    "        if self.max_batch_size and batch_size > self.max_batch_size:\n",
    "            batch_size = self.max_batch_size\n",
    "        batched_embeddings = []\n",
    "        if task is not None:  # noqa\n",
    "            instruction = task_to_instruction(task)\n",
    "        else:\n",
    "            instruction = \"\"\n",
    "            \n",
    "        for batch in tqdm(batched(sentences, batch_size)):\n",
    "            with torch.inference_mode():\n",
    "                batch_dict = self.preprocess(batch, instruction=instruction, encode_type=encode_type)\n",
    "                outputs = self.model(**batch_dict)\n",
    "                embeddings = self.get_embedding_from_output(outputs, batch_dict)\n",
    "            batched_embeddings.append(embeddings.detach().cpu())\n",
    "\n",
    "        return torch.cat(batched_embeddings).to(\"cpu\").detach().numpy()\n",
    "\n",
    "    def encode_corpus(self, corpus: list[dict[str, str]], **kwargs: Any) -> np.ndarray:\n",
    "        sep = \" \"\n",
    "        if isinstance(corpus, dict):\n",
    "            sentences = [\n",
    "                (corpus[\"title\"][i] + sep + corpus[\"text\"][i]).strip() if \"title\" in corpus else corpus[\"text\"][i].strip()  # type: ignore\n",
    "                for i in range(len(corpus[\"text\"]))  # type: ignore\n",
    "            ]\n",
    "        else:\n",
    "            sentences = [(doc[\"title\"] + sep + doc[\"text\"]).strip() if \"title\" in doc else doc[\"text\"].strip() for doc in corpus]\n",
    "        return self.encode(sentences, encode_type=\"passage\", **kwargs)\n",
    "\n",
    "    def encode_queries(self, queries: list[str], **kwargs: Any) -> np.ndarray:\n",
    "        return self.encode(queries, encode_type=\"query\", **kwargs)\n",
    "\n",
    "\n",
    "class Llama8BInstruct(E5Instruct):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"meta-llama/Meta-Llama-3-8B-Instruct\", max_length=512, max_batch_size=32, torch_dtype=torch.float16)\n",
    "\n",
    "    @staticmethod\n",
    "    def last_token_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "        left_padding = attention_mask[:, -1].sum() == attention_mask.shape[0]\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[\n",
    "            torch.arange(batch_size, device=last_hidden_states.device),\n",
    "            sequence_lengths,\n",
    "        ]\n",
    "\n",
    "    def get_embedding_from_output(self, output: ModelOutput, batch_dict: BatchEncoding) -> torch.Tensor:\n",
    "        return self.last_token_pool(output.last_hidden_state, batch_dict[\"attention_mask\"])  # type: ignore\n",
    "\n",
    "    def preprocess(self, sentences: Sequence[str], instruction: str, encode_type: EncodeTypes) -> BatchEncoding:\n",
    "        if encode_type == \"query\":\n",
    "            sentences = [f\"Instruction: {instruction}\\nQuery: {sentence}\" for sentence in sentences]\n",
    "        \n",
    "        batch_dict: BatchEncoding = self.tokenizer(\n",
    "            sentences,  # type: ignore\n",
    "            max_length=self.max_length - 1,\n",
    "            return_attention_mask=False,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        # append eos_token_id to every input_ids\n",
    "        batch_dict[\"input_ids\"] = [\n",
    "            [*input_ids, self.tokenizer.eos_token_id]\n",
    "            for input_ids in batch_dict[\"input_ids\"]  # type: ignore\n",
    "        ]\n",
    "        batch_dict = self.tokenizer.pad(batch_dict, padding=True, return_attention_mask=True, return_tensors=\"pt\")\n",
    "\n",
    "        return batch_dict.to(self.model.device)\n",
    "\n",
    "\n",
    "@models.register(\"llama-8b-instruct\")\n",
    "def create_llama_8b_instruct() -> SebModel:\n",
    "    hf_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    meta = ModelMeta(\n",
    "        name=hf_name.split(\"/\")[-1],\n",
    "        huggingface_name=hf_name,\n",
    "        reference=f\"https://huggingface.co/{hf_name}\",\n",
    "        languages=[],\n",
    "        open_source=True,\n",
    "        embedding_size=4096,\n",
    "        architecture=\"Llama\",\n",
    "        release_date=date(2023, 12, 20),\n",
    "    )\n",
    "    return SebModel(\n",
    "        encoder=LazyLoadEncoder(Llama8BInstruct),\n",
    "        meta=meta,\n",
    "    )\n",
    "\n",
    "model_name = \"llama-8b-instruct\"\n",
    "#def run_benchmark():\n",
    "models = [seb.get_model(model_name)]\n",
    "benchmark = seb.Benchmark(languages=['da'])\n",
    "results = benchmark.evaluate_models(models=models)\n",
    "#Save pickle\n",
    "with open(f\"SEB_eval_{model_name}.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "avg_score = np.mean([res.get_main_score() for res in results])\n",
    "print(f'\\nAverage results: {avg_score}')\n",
    "print(f'\\nFull Results:\\n{results}')\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Any, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from transformers import AutoModel, AutoTokenizer, BatchEncoding\n",
    "from tqdm import tqdm\n",
    "\n",
    "class OptimizedLlama8BInstruct(Encoder):\n",
    "    def __init__(self, model_name: str, pooling_mode: str = \"mean\", max_length: int = 512, skip_instruction: bool = True):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.max_length = max_length\n",
    "        self.pooling_mode = pooling_mode\n",
    "        self.skip_instruction = skip_instruction\n",
    "\n",
    "        # Handle PAD token\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def preprocess(\n",
    "        self, \n",
    "        sentences: List[str], \n",
    "        instruction: str = \"\", \n",
    "        encode_type: str = \"query\"\n",
    "    ) -> BatchEncoding:\n",
    "        # Attach instruction dynamically\n",
    "        if encode_type == \"query\" and instruction:\n",
    "            sentences = [f\"Instruction: {instruction}\\nQuery: {sentence}\" for sentence in sentences]\n",
    "        \n",
    "        # Tokenize sentences in a single call\n",
    "        tokens = self.tokenizer(\n",
    "            sentences,\n",
    "            max_length=self.max_length,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return tokens\n",
    "\n",
    "    def forward(self, batch_encoding: BatchEncoding) -> Tensor:\n",
    "        # Perform the forward pass and return embeddings\n",
    "        outputs = self.model(**batch_encoding)\n",
    "        return self.pool_embeddings(outputs.last_hidden_state, batch_encoding[\"attention_mask\"])\n",
    "\n",
    "    def pool_embeddings(self, hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "        # Handle pooling based on the chosen strategy\n",
    "        if self.pooling_mode == \"mean\":\n",
    "            # Mask unwanted tokens and compute mean\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "            summed = torch.sum(hidden_states * mask_expanded, dim=1)\n",
    "            summed_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)  # Avoid divide-by-zero\n",
    "            return summed / summed_mask\n",
    "\n",
    "        elif self.pooling_mode == \"eos_token\":\n",
    "            # Return the last hidden states for tokens\n",
    "            eos_positions = attention_mask.sum(dim=1) - 1\n",
    "            return hidden_states[torch.arange(hidden_states.size(0)), eos_positions]\n",
    "\n",
    "        elif self.pooling_mode == \"last_token\":\n",
    "            # Simply take the last hidden state\n",
    "            return hidden_states[:, -1]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Pooling mode '{self.pooling_mode}' is not recognized\")\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        sentences: List[str],\n",
    "        batch_size: int = 32,\n",
    "        encode_type: str = \"query\",\n",
    "        instruction: str = \"\",\n",
    "        show_progress_bar: bool = True,\n",
    "        device: str = \"cuda\",\n",
    "    ) -> np.ndarray:\n",
    "        self.model.to(device)\n",
    "        self.eval()\n",
    "\n",
    "        all_embeddings = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm([sentences[i:i + batch_size] for i in range(0, len(sentences), batch_size)], disable=not show_progress_bar):\n",
    "                batch_tokens = self.preprocess(batch, instruction=instruction, encode_type=encode_type)\n",
    "                batch_tokens = {k: v.to(device) for k, v in batch_tokens.items()}  # Move to GPU\n",
    "                embeddings = self.forward(batch_tokens)\n",
    "                all_embeddings.append(embeddings.cpu())  # Move to CPU after computation\n",
    "\n",
    "        return torch.cat(all_embeddings, dim=0).numpy()\n",
    "\n",
    "    def encode_queries(self, queries: List[str], **kwargs) -> np.ndarray:\n",
    "        return self.encode(queries, encode_type=\"query\", **kwargs)\n",
    "\n",
    "    def encode_corpus(self, corpus: List[Dict[str, str]], **kwargs) -> np.ndarray:\n",
    "        sentences = [\n",
    "            (doc[\"title\"] + \" \" + doc[\"text\"]).strip() if \"title\" in doc else doc[\"text\"].strip()\n",
    "            for doc in corpus\n",
    "        ]\n",
    "        return self.encode(sentences, encode_type=\"passage\", **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'register'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@models\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-8b-instruct-optimized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_llama_8b_instruct\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SebModel:\n\u001b[1;32m      3\u001b[0m     hf_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     meta \u001b[38;5;241m=\u001b[39m ModelMeta(\n\u001b[1;32m      5\u001b[0m         name\u001b[38;5;241m=\u001b[39mhf_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      6\u001b[0m         huggingface_name\u001b[38;5;241m=\u001b[39mhf_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         release_date\u001b[38;5;241m=\u001b[39mdate(\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m     13\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'register'"
     ]
    }
   ],
   "source": [
    "@models.register(\"llama-8b-instruct-optimized\")\n",
    "def create_llama_8b_instruct() -> SebModel:\n",
    "    hf_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    meta = ModelMeta(\n",
    "        name=hf_name.split(\"/\")[-1],\n",
    "        huggingface_name=hf_name,\n",
    "        reference=f\"https://huggingface.co/{hf_name}\",\n",
    "        languages=[],\n",
    "        open_source=True,\n",
    "        embedding_size=4096,\n",
    "        architecture=\"Llama\",\n",
    "        release_date=date(2023, 12, 20),\n",
    "    )\n",
    "    return SebModel(\n",
    "        encoder=LazyLoadEncoder(OptimizedLlama8BInstruct),\n",
    "        meta=meta,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama-8b-instruct\"\n",
    "#def run_benchmark():\n",
    "models = [seb.get_model(model_name)]\n",
    "benchmark = seb.Benchmark(languages=['da'])\n",
    "results = benchmark.evaluate_models(models=models)\n",
    "#Save pickle\n",
    "with open(f\"SEB_eval_{model_name}.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "avg_score = np.mean([res.get_main_score() for res in results])\n",
    "print(f'\\nAverage results: {avg_score}')\n",
    "print(f'\\nFull Results:\\n{results}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
